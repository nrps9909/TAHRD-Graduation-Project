{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6935937c-3b03-413d-9681-bb6e8f72180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:39:09,872 - 正在初始化情感分類器（j-hartmann/emotion-english-distilroberta-base）...\n",
      "Device set to use cuda:0\n",
      "2025-03-28 15:39:10,642 - 正在初始化零樣本分類器...\n",
      "Device set to use cuda:1\n",
      "讀取聊天檔案:   0%|          | 0/1 [00:00<?, ?it/s]2025-03-28 15:39:12,517 - 成功讀取檔案: data/claire.txt\n",
      "讀取聊天檔案: 100%|██████████| 1/1 [00:00<00:00, 284.92it/s]\n",
      "解析聊天檔案:   0%|          | 0/1 [00:00<?, ?it/s]2025-03-28 15:39:12,524 - 開始解析聊天記錄 (User: 0, Friend: 2)...\n",
      "\n",
      "解析聊天行: 100%|██████████| 2014/2014 [00:00<00:00, 200449.15it/s]\n",
      "2025-03-28 15:39:12,540 - 解析完成，生成 116 組對話\n",
      "解析聊天檔案: 100%|██████████| 1/1 [00:00<00:00, 47.89it/s]\n",
      "2025-03-28 15:39:12,543 - 從快取檔案 embeddings.pt 載入嵌入向量...\n",
      "2025-03-28 15:39:12,547 - 開始添加情緒標籤...\n",
      "2025-03-28 15:39:12,608 - 開始全批量情感分類...\n",
      "情感分類批次處理: 100%|██████████| 12/12 [00:02<00:00,  4.14it/s]\n",
      "組裝情感標籤: 100%|██████████| 116/116 [00:00<00:00, 7498.37it/s]\n",
      "2025-03-28 15:39:15,528 - 情感標籤添加完成\n",
      "2025-03-28 15:39:15,530 - 開始添加話題標籤...\n",
      "2025-03-28 15:39:15,545 - 開始全批量話題分類...\n",
      "話題分類批次處理: 100%|██████████| 12/12 [00:48<00:00,  4.07s/it]\n",
      "組裝話題標籤: 100%|██████████| 116/116 [00:00<00:00, 872.88it/s]\n",
      "2025-03-28 15:40:04,552 - 話題標籤添加完成\n",
      "2025-03-28 15:40:04,554 - 開始混合對話...\n",
      "混合對話: 100%|██████████| 1486/1486 [00:00<00:00, 906975.52it/s]\n",
      "2025-03-28 15:40:04,560 - 混合完成，生成 385 組對話\n",
      "2025-03-28 15:40:04,561 - 開始格式化訓練資料...\n",
      "2025-03-28 15:40:04,563 - 預先批量計算所有對話行為...\n",
      "2025-03-28 15:40:04,578 - 正在對 1486 條訊息進行對話行為分類，批次大小: 128\n",
      "行為分類批次處理: 100%|██████████| 12/12 [01:15<00:00,  6.30s/it]\n",
      "後處理對話行為: 100%|██████████| 1486/1486 [00:00<00:00, 7969.99it/s]\n",
      "格式化對話組: 100%|██████████| 385/385 [00:00<00:00, 7741.57it/s]\n",
      "2025-03-28 15:41:20,377 - 格式化完成，生成 645 筆訓練資料\n",
      "2025-03-28 15:41:20,389 - 訓練資料已儲存至 output/out.json，總共 645 筆資料\n",
      "2025-03-28 15:41:20,393 - 前 3 筆訓練資料範例：\n",
      "2025-03-28 15:41:20,394 - 樣本 1:\n",
      "2025-03-28 15:41:20,395 - Prompt: User0: 啊他到底有沒有女朋友 [情緒: 焦慮, 行為: 告別, 話題: 人際+感情八卦]\n",
      "2025-03-28 15:41:20,397 - Response: 他顏值真的很高🥺🥺🥺 [情緒: 喜愛, 行為: 讚美, 話題: 人際+感情八卦]\n",
      "2025-03-28 15:41:20,398 - 樣本 2:\n",
      "2025-03-28 15:41:20,399 - Prompt: User0: 啊他到底有沒有女朋友 [情緒: 焦慮, 行為: 告別, 話題: 人際+感情八卦]\n",
      "User0: 他顏值真的很高🥺🥺🥺 [情緒: 喜愛, 行為: 讚美, 話題: 人際+感情八卦]\n",
      "2025-03-28 15:41:20,400 - Response: 雖然我覺得 [情緒: 中性, 行為: 補充, 話題: 人際+感情八卦]\n",
      "2025-03-28 15:41:20,402 - 樣本 3:\n",
      "2025-03-28 15:41:20,402 - Prompt: User0: 啊他到底有沒有女朋友 [情緒: 焦慮, 行為: 告別, 話題: 人際+感情八卦]\n",
      "User0: 他顏值真的很高🥺🥺🥺 [情緒: 喜愛, 行為: 讚美, 話題: 人際+感情八卦]\n",
      "User0: 雖然我覺得 [情緒: 中性, 行為: 補充, 話題: 人際+感情八卦]\n",
      "User0: 很冷淡 [情緒: 難過, 行為: 表達情感, 話題: 人際+感情八卦]\n",
      "2025-03-28 15:41:20,404 - Response: 但他會理大一的男生 [情緒: 中性, 行為: 其他, 話題: 人際]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import List, Tuple\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import logging\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import emoji\n",
    "import os\n",
    "import opencc\n",
    "from functools import lru_cache\n",
    "\n",
    "# 設置記憶體管理環境變數\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# 設置日誌\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 初始化多 GPU 環境\n",
    "device_ids = [0, 1]  # 兩張 A10G\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 清理 GPU 記憶體\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 定義分類標籤\n",
    "act_labels = [\"提問\", \"補充\", \"引入\", \"表達情感\", \"讚美\", \"道歉\", \"感謝\", \"請求\", \"拒絕\", \"建議\", \"問候\", \"告別\", \"確認\", \"表達意圖\", \"吐槽\", \"催促\", \"安慰\", \"接梗\", \"回答\", \"提及\", \"其他\"]\n",
    "topic_labels = [\"活動\", \"感情\", \"學業\", \"娛樂\", \"人際\", \"課業壓力\", \"社團活動\", \"感情八卦\", \"生活瑣事\", \"科技\", \"健康\", \"旅行\"]\n",
    "\n",
    "# 初始化簡繁轉換器\n",
    "converter_to_simplified = opencc.OpenCC('t2s')\n",
    "converter_to_traditional = opencc.OpenCC('s2t')\n",
    "\n",
    "# 動態批次大小\n",
    "def get_dynamic_batch_size(messages: List[str], base_batch_size: int = 128) -> int:\n",
    "    gpu_memory = torch.cuda.memory_reserved(device) / 1024**3\n",
    "    max_memory = 24  # A10G 24GB\n",
    "    if gpu_memory > max_memory * 0.8:\n",
    "        return max(16, base_batch_size // 2)\n",
    "    return base_batch_size\n",
    "\n",
    "# 單進程分片計算嵌入\n",
    "@lru_cache(maxsize=1)\n",
    "def load_embedder():\n",
    "    return SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def compute_chunk(chunk: List[str], gpu_id: int, batch_size: int, embedder: SentenceTransformer) -> torch.Tensor:\n",
    "    torch.cuda.set_device(gpu_id)\n",
    "    embedder.to(f\"cuda:{gpu_id}\")\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            embeddings = embedder.encode(chunk, convert_to_tensor=True, batch_size=batch_size, show_progress_bar=False)\n",
    "            embeddings = embeddings.to(\"cuda:0\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            return embeddings\n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            logger.warning(f\"GPU {gpu_id} 記憶體不足，減半批次大小重試...\")\n",
    "            embeddings = embedder.encode(chunk, convert_to_tensor=True, batch_size=batch_size // 2, show_progress_bar=False)\n",
    "            embeddings = embeddings.to(\"cuda:0\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            return embeddings\n",
    "\n",
    "def precompute_embeddings(messages: List[str], num_gpus: int = 2, chunk_size: int = 5000, cache_file: str = \"embeddings.pt\") -> torch.Tensor:\n",
    "    if os.path.exists(cache_file):\n",
    "        logger.info(f\"從快取檔案 {cache_file} 載入嵌入向量...\")\n",
    "        return torch.load(cache_file)\n",
    "    \n",
    "    logger.info(f\"開始預計算 {len(messages)} 條訊息的嵌入向量...\")\n",
    "    simplified_messages = [converter_to_simplified.convert(msg) for msg in messages]\n",
    "    chunks = [simplified_messages[i:i + chunk_size] for i in range(0, len(messages), chunk_size)]\n",
    "    batch_size = get_dynamic_batch_size(messages)\n",
    "    \n",
    "    embedder = load_embedder()\n",
    "    results = []\n",
    "    \n",
    "    for i, chunk in enumerate(tqdm(chunks, desc=\"計算嵌入分片\")):\n",
    "        gpu_id = device_ids[i % num_gpus]\n",
    "        logger.info(f\"處理分片 {i+1}/{len(chunks)} on GPU {gpu_id}\")\n",
    "        chunk_embeddings = compute_chunk(chunk, gpu_id, batch_size, embedder)\n",
    "        results.append(chunk_embeddings)\n",
    "    \n",
    "    embeddings = torch.cat(results, dim=0)\n",
    "    embeddings = embeddings.cpu()\n",
    "    torch.save(embeddings, cache_file)\n",
    "    logger.info(f\"嵌入計算完成，已儲存至 {cache_file}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return embeddings\n",
    "\n",
    "# 清洗文本\n",
    "def clean_text(text: str) -> str:\n",
    "    if not text or len(text.strip()) < 3 or \"[語音訊息]\" in text:\n",
    "        return \"\"\n",
    "    patterns = r'(上午|下午)\\d{1,2}:\\d{2}\\s*|\\[照片\\]|\\[影片\\]|\\[貼圖\\]|.*已收回訊息.*|☎.*|^\\*+$'\n",
    "    return re.sub(patterns, '', text).strip()\n",
    "\n",
    "# 關鍵詞分類（擴展行為與話題）\n",
    "def keyword_infer_dialogue_act(message: str, prev_act: str = None) -> str:\n",
    "    message_lower = message.lower()\n",
    "    keywords = {\n",
    "        \"提問\": ['有沒有', '什麼', '會不會', '你覺得', '怎麼', '為什麼', '嗎', '哪個', '可不可以', '到了沒', '幾點', '到底', '知道', '多少', '誰', '哪裡', '咩', '欸？'],\n",
    "        \"補充\": ['因為', '所以', '雖然', '不過', '但是', '然後', '而且', '結果', '還有', '就', '其實', '剛剛', '出來', '聽到', '天才', '之前'],\n",
    "        \"引入\": ['重點是', '主要是', '說到', '講到', '提到', '我也不知道', '話說'],\n",
    "        \"表達情感\": ['難過', '尷尬', '自豪', '麻煩', '緊張', '開心', '笑死', '希望', '怕', '覺得', '累了', '冷淡', '好笑', '靠北', '你娘', '超趕', '超好笑', '恨', '想哭', '啊啊', '嚇死', '聊不起來'],\n",
    "        \"讚美\": ['漂亮', '帥', '很棒', '很讚', '很可愛', '適合', '好會', '好一點', '顏值', '很高'],\n",
    "        \"道歉\": ['對不起', '抱歉', '不好意思', 'sorry'],\n",
    "        \"感謝\": ['謝謝', '感謝', '感激', '多謝'],\n",
    "        \"請求\": ['拜託', '請', '幫我', '可以嗎'],\n",
    "        \"拒絕\": ['不要', '不行', '不可以', '不ok', '沒辦法', '不會', '我沒'],\n",
    "        \"建議\": ['建議', '不如', '要不要', '不然', '等等再', '應該'],\n",
    "        \"問候\": ['嗨', '嘿', '你好', '早安'],\n",
    "        \"告別\": ['掰掰', '拜拜', '再見', '晚安', '解散', '出門', '你刪掉啊'],\n",
    "        \"確認\": ['真的假的', '確定', '確認', '好啦', '是嗎', '不確定'],\n",
    "        \"表達意圖\": ['我要', '我想', '我會', '可能', '不可能'],\n",
    "        \"吐槽\": ['笑死', '怎麼可能', '超醜', '靠腰', '你快點', '智障', '扁你'],\n",
    "        \"催促\": ['快點', '最好快點', '趕緊', '供三信'],\n",
    "        \"安慰\": ['不會吧', '又沒差', '沒事的'],\n",
    "        \"接梗\": ['超好笑', '哈哈哈', '我也是', '後來也換'],\n",
    "        \"回答\": ['是', '不是', '對', '錯', '好', '嗯', '喔', '應該', '沒有'],\n",
    "        \"提及\": ['許恩開', '陳姿佑', '呂忠言', '張少權', '李冠毅', '尹俊翔', '蔡', '賀哥', '魏氏凱', '余葶', '理工男']\n",
    "    }\n",
    "    # 優先檢查提問\n",
    "    if any(kw in message_lower for kw in keywords[\"提問\"]):\n",
    "        return \"提問\"\n",
    "    for act, kws in keywords.items():\n",
    "        if act != \"提問\" and any(kw in message_lower for kw in kws):\n",
    "            return act\n",
    "    # 上下文檢查\n",
    "    if prev_act == \"提問\" and not any(kw in message_lower for kw in keywords[\"提問\"]):\n",
    "        return \"其他\"\n",
    "    return \"其他\"\n",
    "\n",
    "# 初始化分類器\n",
    "logger.info(\"正在初始化情感分類器（j-hartmann/emotion-english-distilroberta-base）...\")\n",
    "sentiment_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    device=device_ids[0],\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    top_k=None\n",
    ")\n",
    "\n",
    "logger.info(\"正在初始化零樣本分類器...\")\n",
    "zero_shot_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\",\n",
    "    device=device_ids[1],\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "# 對話行為分類\n",
    "def infer_dialogue_act(messages: List[str], prev_acts: List[str] = None, embeddings: torch.Tensor = None) -> List[str]:\n",
    "    if prev_acts is None:\n",
    "        prev_acts = [None] * len(messages)\n",
    "    \n",
    "    simplified_messages = [converter_to_simplified.convert(msg) for msg in messages]\n",
    "    batch_size = get_dynamic_batch_size(messages)\n",
    "    logger.info(f\"正在對 {len(messages)} 條訊息進行對話行為分類，批次大小: {batch_size}\")\n",
    "    \n",
    "    num_batches = (len(messages) + batch_size - 1) // batch_size\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(messages), batch_size), total=num_batches, desc=\"行為分類批次處理\"):\n",
    "            batch = simplified_messages[i:i + batch_size]\n",
    "            batch_results = zero_shot_classifier(batch, act_labels, multi_label=False, batch_size=len(batch))\n",
    "            results.extend(batch_results)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "    \n",
    "    predicted_acts = []\n",
    "    for i, (message, prev_act, result) in tqdm(enumerate(zip(messages, prev_acts, results)), total=len(messages), desc=\"後處理對話行為\"):\n",
    "        predicted_act = result['labels'][0]\n",
    "        confidence = result['scores'][0]\n",
    "        \n",
    "        if confidence < 0.3 and embeddings is not None and i > 0:\n",
    "            similarity = util.cos_sim(embeddings[i], embeddings[i-1]).item()\n",
    "            if similarity > 0.7 and prev_acts[i-1]:\n",
    "                predicted_act = prev_acts[i-1]\n",
    "            else:\n",
    "                predicted_act = keyword_infer_dialogue_act(message, prev_act)\n",
    "        elif prev_act == \"提問\" and predicted_act not in [\"提問\", \"補充\", \"回答\"]:\n",
    "            predicted_act = \"其他\"\n",
    "        \n",
    "        predicted_acts.append(predicted_act if predicted_act else \"其他\")\n",
    "    return predicted_acts\n",
    "\n",
    "# 解析聊天記錄\n",
    "def parse_chat_log(chat_log: str, user_id: str, friend_id: str, time_threshold: int = 5) -> List[List[Tuple[str, str, int]]]:\n",
    "    lines = [line.strip() for line in chat_log.split('\\n') if line.strip() and \"儲存日期\" not in line and not re.match(r'\\d{4}/\\d{2}/\\d{2}', line)]\n",
    "    conversation_groups = []\n",
    "    current_group = []\n",
    "    prev_time = None\n",
    "    \n",
    "    logger.info(f\"開始解析聊天記錄 (User: {user_id}, Friend: {friend_id})...\")\n",
    "    for line in tqdm(lines, desc=\"解析聊天行\"):\n",
    "        match = re.match(r'(上午|下午)(\\d{1,2}):(\\d{2})\\s*([A-B])\\s+(.+)', line)\n",
    "        if match:\n",
    "            period, hour, minute, speaker, message = match.groups()\n",
    "            cleaned_message = clean_text(message)\n",
    "            if cleaned_message:\n",
    "                current_time = int(hour) * 60 + int(minute) + (12 * 60 if period == \"下午\" else 0)\n",
    "                if prev_time and abs(current_time - prev_time) > time_threshold:\n",
    "                    conversation_groups.append(current_group)\n",
    "                    current_group = []\n",
    "                role = f\"User{user_id}\" if speaker == \"B\" else f\"User{friend_id}\"\n",
    "                current_group.append((role, cleaned_message, current_time))\n",
    "                prev_time = current_time\n",
    "    \n",
    "    if current_group:\n",
    "        conversation_groups.append(current_group)\n",
    "    logger.info(f\"解析完成，生成 {len(conversation_groups)} 組對話\")\n",
    "    return conversation_groups\n",
    "\n",
    "# 添加情緒標籤\n",
    "def add_emotion_labels(conversation_groups: List[List[Tuple[str, str, int]]], embeddings: torch.Tensor) -> List[List[Tuple[str, str, int, str]]]:\n",
    "    all_messages = [emoji.demojize(msg) for group in conversation_groups for _, msg, _ in group]\n",
    "    simplified_messages = [converter_to_simplified.convert(msg) for msg in all_messages]\n",
    "    batch_size = get_dynamic_batch_size(all_messages)\n",
    "    logger.info(\"開始全批量情感分類...\")\n",
    "    num_batches = (len(all_messages) + batch_size - 1) // batch_size\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(all_messages), batch_size), total=num_batches, desc=\"情感分類批次處理\"):\n",
    "            batch = simplified_messages[i:i + batch_size]\n",
    "            batch_results = sentiment_classifier(batch, batch_size=len(batch), truncation=True, max_length=128)\n",
    "            results.extend(batch_results)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "    \n",
    "    labeled_groups = [[] for _ in conversation_groups]\n",
    "    emotion_map = {\n",
    "        'joy': '開心', 'sadness': '難過', 'anger': '憤怒', 'fear': '害怕', 'love': '喜愛', \n",
    "        'surprise': '驚訝', 'neutral': '中性', ':smiling_face_with_heart-eyes:': '喜愛', \n",
    "        ':pouting_face:': '難過', ':laughing:': '開心', ':sob:': '難過', ':angry_face:': '憤怒',\n",
    "        ':face_with_tears_of_joy:': '開心', ':pleading_face:': '喜愛', ':scream:': '興奮', \n",
    "        ':thinking_face:': '焦慮', ':weary_face:': '無奈', ':sleeping_face:': '懶散'\n",
    "    }\n",
    "    msg_idx = 0\n",
    "    for group_idx, group in enumerate(tqdm(conversation_groups, desc=\"組裝情感標籤\")):\n",
    "        for speaker, message, time in group:\n",
    "            sentiment_scores = results[msg_idx]\n",
    "            top_emotion = max(sentiment_scores, key=lambda x: x['score'])['label']\n",
    "            confidence = max(sentiment_scores, key=lambda x: x['score'])['score']\n",
    "            emotion = emotion_map.get(top_emotion, '中性')\n",
    "            # 檢查表情符號\n",
    "            for emoji_key, emo in emotion_map.items():\n",
    "                if emoji_key in message and emo != '中性':\n",
    "                    emotion = emo\n",
    "                    break\n",
    "            # 增強上下文推理\n",
    "            if confidence < 0.5 and msg_idx > 0:\n",
    "                similarity = util.cos_sim(embeddings[msg_idx], embeddings[msg_idx-1]).item()\n",
    "                if similarity > 0.7:\n",
    "                    emotion = labeled_groups[group_idx][-1][3] if labeled_groups[group_idx] else '中性'\n",
    "            # 關鍵詞後處理\n",
    "            message_lower = message.lower()\n",
    "            if '笑死' in message_lower or '好笑' in message_lower or '哈哈' in message_lower:\n",
    "                emotion = '開心' if '超' not in message_lower else '興奮'\n",
    "            elif '難過' in message_lower or '尷尬' in message_lower or '怕' in message_lower or '冷淡' in message_lower or '想哭' in message_lower:\n",
    "                emotion = '難過'\n",
    "            elif '嚇死' in message_lower:\n",
    "                emotion = '害怕'\n",
    "            elif '扁你' in message_lower:\n",
    "                emotion = '憤怒'\n",
    "            elif '沒安全感' in message_lower:\n",
    "                emotion = '焦慮'\n",
    "            elif '很高' in message_lower and '顏值' in message_lower:\n",
    "                emotion = '喜愛'\n",
    "            elif '你娘' in message_lower or '靠北' in message_lower or '耖你媽' in message_lower:\n",
    "                emotion = '難過' if '笑' not in message_lower else '開心'\n",
    "            elif '怎麼辦' in message_lower or '到底' in message_lower or '超趕' in message_lower:\n",
    "                emotion = '焦慮'\n",
    "            elif '我要睡了' in message_lower or '又沒差' in message_lower:\n",
    "                emotion = '懶散'\n",
    "            elif '去宜蘭玩' in message_lower or '超好笑' in message_lower:\n",
    "                emotion = '興奮' if '超' in message_lower else '開心'\n",
    "            elif '我沒準備' in message_lower or '我他媽' in message_lower or '超醜' in message_lower or '減肥' in message_lower:\n",
    "                emotion = '焦慮' if '怎麼辦' in message_lower else '無奈'\n",
    "            elif '不知道' in message_lower or '搞不好' in message_lower:\n",
    "                emotion = '困惑'\n",
    "            elif '超級冷' in message_lower and '好' not in message_lower:\n",
    "                emotion = '難過'\n",
    "            labeled_groups[group_idx].append((speaker, message, time, emotion))\n",
    "            msg_idx += 1\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    logger.info(\"情感標籤添加完成\")\n",
    "    return labeled_groups\n",
    "\n",
    "# 添加話題標籤\n",
    "def add_topic_labels(conversation_groups: List[List[Tuple[str, str, int, str]]], embeddings: torch.Tensor) -> List[List[Tuple[str, str, int, str, str]]]:\n",
    "    all_messages = [msg for group in conversation_groups for _, msg, _, _ in group]\n",
    "    simplified_messages = [converter_to_simplified.convert(msg) for msg in all_messages]\n",
    "    batch_size = get_dynamic_batch_size(all_messages)\n",
    "    logger.info(\"開始全批量話題分類...\")\n",
    "    num_batches = (len(all_messages) + batch_size - 1) // batch_size\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(all_messages), batch_size), total=num_batches, desc=\"話題分類批次處理\"):\n",
    "            batch = simplified_messages[i:i + batch_size]\n",
    "            batch_results = zero_shot_classifier(batch, topic_labels, multi_label=True, batch_size=len(batch))\n",
    "            results.extend(batch_results)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "    \n",
    "    labeled_groups = [[] for _ in conversation_groups]\n",
    "    msg_idx = 0\n",
    "    for group_idx, group in enumerate(tqdm(conversation_groups, desc=\"組裝話題標籤\")):\n",
    "        for speaker, message, time, emotion in group:\n",
    "            result = results[msg_idx]\n",
    "            predicted_topics = sorted([(label, score) for label, score in zip(result['labels'], result['scores'])], key=lambda x: x[1], reverse=True)[:2]\n",
    "            predicted_topics = [label for label, score in predicted_topics if score > 0.4]\n",
    "            message_lower = message.lower()\n",
    "            if '女朋友' in message_lower or '喜歡' in message_lower or '在一起' in message_lower or '約會' in message_lower or 'fu' in message_lower or '曖昧' in message_lower:\n",
    "                predicted_topics.append('感情八卦')\n",
    "            if '群組' in message_lower or '男生' in message_lower or '女生' in message_lower or '室友' in message_lower or '朋友' in message_lower:\n",
    "                predicted_topics.append('人際')\n",
    "            if '笑死' in message_lower or '好笑' in message_lower or '照片' in message_lower or '電影' in message_lower or '超好笑' in message_lower:\n",
    "                predicted_topics.append('娛樂')\n",
    "            if '遊覽車' in message_lower or '出去玩' in message_lower or '計畫' in message_lower or '活動' in message_lower or '參加' in message_lower:\n",
    "                predicted_topics.append('社團活動')\n",
    "            if '填' in message_lower or '名額' in message_lower or '家教' in message_lower or '考試' in message_lower or '進度' in message_lower:\n",
    "                predicted_topics.append('課業壓力')\n",
    "            if '睡了' in message_lower or '洗澡' in message_lower or '行李' in message_lower or '出門' in message_lower or '吃飯' in message_lower or '起床' in message_lower:\n",
    "                predicted_topics.append('生活瑣事')\n",
    "            if '手機' in message_lower or '電腦' in message_lower or '科技' in message_lower or '版本' in message_lower:\n",
    "                predicted_topics.append('科技')\n",
    "            if '健康' in message_lower or '運動' in message_lower or '生病' in message_lower or '暈車' in message_lower:\n",
    "                predicted_topics.append('健康')\n",
    "            if '桃園' in message_lower or '宜蘭' in message_lower or '走路' in message_lower or '車上' in message_lower or '台中' in message_lower or '台北' in message_lower:\n",
    "                predicted_topics.append('旅行')\n",
    "            if not predicted_topics and msg_idx > 0:\n",
    "                similarity = util.cos_sim(embeddings[msg_idx], embeddings[msg_idx-1]).item()\n",
    "                if similarity > 0.7:\n",
    "                    topic_str = labeled_groups[group_idx][-1][4] if labeled_groups[group_idx] else \"日常\"\n",
    "                else:\n",
    "                    topic_str = \"日常\"\n",
    "            else:\n",
    "                topic_str = \"+\".join(sorted(set(predicted_topics[:2]))) if predicted_topics else \"日常\"\n",
    "            labeled_groups[group_idx].append((speaker, message, time, emotion, topic_str))\n",
    "            msg_idx += 1\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    logger.info(\"話題標籤添加完成\")\n",
    "    return labeled_groups\n",
    "\n",
    "# 優化格式化訓練數據\n",
    "def format_training_data(conversation_groups: List[List[Tuple[str, str, int, str, str]]], embeddings: torch.Tensor, max_turns: int = 10, similarity_threshold: float = 0.7) -> List[dict]:\n",
    "    training_data = []\n",
    "    msg_idx = 0\n",
    "    \n",
    "    logger.info(\"開始格式化訓練資料...\")\n",
    "    all_messages = [item[1] for group in conversation_groups for item in group]\n",
    "    logger.info(\"預先批量計算所有對話行為...\")\n",
    "    all_dialogue_acts = infer_dialogue_act(all_messages, embeddings=embeddings)\n",
    "    act_idx = 0\n",
    "    \n",
    "    for group in tqdm(conversation_groups, desc=\"格式化對話組\"):\n",
    "        messages = [item[1] for item in group]\n",
    "        dialogue_acts = all_dialogue_acts[act_idx:act_idx + len(messages)]\n",
    "        act_idx += len(messages)\n",
    "        \n",
    "        if len(messages) > 1:\n",
    "            curr_embeddings = embeddings[msg_idx:msg_idx + len(messages) - 1]\n",
    "            next_embeddings = embeddings[msg_idx + 1:msg_idx + len(messages)]\n",
    "            similarities = util.cos_sim(curr_embeddings, next_embeddings).diagonal().cpu().numpy()\n",
    "        else:\n",
    "            similarities = np.array([])\n",
    "        \n",
    "        for i in range(len(group) - 1):\n",
    "            context = group[max(0, i - max_turns + 1):i + 1]\n",
    "            next_msg = group[i + 1]\n",
    "            similarity = similarities[i] if i < len(similarities) else 0.0\n",
    "            \n",
    "            # 加強語義完整性和話題一致性檢查\n",
    "            context_topic = context[-1][4].split(\"+\")[0]  # 取主要話題\n",
    "            response_topic = next_msg[4].split(\"+\")[0]\n",
    "            if (similarity >= similarity_threshold and len(next_msg[1]) >= 3 and \n",
    "                any(c in next_msg[1] for c in ['。', '！', '？', '是', '不', '我', '你', '他', '有', '沒']) and\n",
    "                context_topic == response_topic):\n",
    "                prompt = \"\\n\".join(f\"{s}: {m} [情緒: {e}, 行為: {dialogue_acts[j]}, 話題: {t}]\" \n",
    "                                 for j, (s, m, _, e, t) in enumerate(context))\n",
    "                response = f\"{next_msg[1]} [情緒: {next_msg[3]}, 行為: {dialogue_acts[i + 1]}, 話題: {next_msg[4]}]\"\n",
    "                training_data.append({\"prompt\": prompt, \"response\": response})\n",
    "        msg_idx += len(group)\n",
    "    \n",
    "    logger.info(f\"格式化完成，生成 {len(training_data)} 筆訓練資料\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return training_data\n",
    "\n",
    "# 混合多人群聊\n",
    "def mix_conversations(chat_logs: List[str], friend_ids: List[str], time_threshold: int = 5, max_turns: int = 10, similarity_threshold: float = 0.7) -> List[dict]:\n",
    "    all_groups = []\n",
    "    for user_id, (chat_log, friend_id) in enumerate(tqdm(zip(chat_logs, friend_ids), desc=\"解析聊天檔案\", total=len(chat_logs))):\n",
    "        groups = parse_chat_log(chat_log, str(user_id), friend_id, time_threshold)\n",
    "        all_groups.extend(groups)\n",
    "    \n",
    "    all_messages = [msg for group in all_groups for _, msg, _ in group]\n",
    "    embeddings = precompute_embeddings(all_messages, num_gpus=2, chunk_size=5000)\n",
    "    \n",
    "    logger.info(\"開始添加情緒標籤...\")\n",
    "    all_groups = add_emotion_labels(all_groups, embeddings)\n",
    "    logger.info(\"開始添加話題標籤...\")\n",
    "    all_groups = add_topic_labels(all_groups, embeddings)\n",
    "    \n",
    "    logger.info(\"開始混合對話...\")\n",
    "    all_conversations = [item for group in all_groups for item in group]\n",
    "    all_conversations.sort(key=lambda x: x[2])\n",
    "    \n",
    "    mixed_groups = []\n",
    "    current_group = []\n",
    "    prev_time = None\n",
    "    prev_topic = None\n",
    "    for item in tqdm(all_conversations, desc=\"混合對話\"):\n",
    "        speaker, message, time, emotion, topic = item\n",
    "        if prev_time and (abs(time - prev_time) > time_threshold or topic.split(\"+\")[0] != prev_topic):\n",
    "            if current_group:\n",
    "                mixed_groups.append(current_group)\n",
    "            current_group = []\n",
    "        current_group.append((speaker, message, time, emotion, topic))\n",
    "        prev_time = time\n",
    "        prev_topic = topic.split(\"+\")[0]\n",
    "    if current_group:\n",
    "        mixed_groups.append(current_group)\n",
    "    \n",
    "    logger.info(f\"混合完成，生成 {len(mixed_groups)} 組對話\")\n",
    "    return format_training_data(mixed_groups, embeddings, max_turns, similarity_threshold)\n",
    "\n",
    "# 主函數\n",
    "def process_chat_to_training_data(chat_files: List[str], friend_ids: List[str], output_file: str, time_threshold: int = 5, max_turns: int = 10, similarity_threshold: float = 0.7):\n",
    "    chat_logs = []\n",
    "    for chat_file in tqdm(chat_files, desc=\"讀取聊天檔案\"):\n",
    "        try:\n",
    "            with open(chat_file, 'r', encoding='utf-8') as f:\n",
    "                chat_logs.append(f.read())\n",
    "            logger.info(f\"成功讀取檔案: {chat_file}\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"找不到檔案: {chat_file}\")\n",
    "            return\n",
    "    \n",
    "    training_data = mix_conversations(chat_logs, friend_ids, time_threshold, max_turns, similarity_threshold)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(training_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    logger.info(f\"訓練資料已儲存至 {output_file}，總共 {len(training_data)} 筆資料\")\n",
    "\n",
    "# 測試用\n",
    "if __name__ == \"__main__\":\n",
    "    chat_files = [\"data/claire.txt\"]\n",
    "    friend_ids = [\"2\"]\n",
    "    output_file = \"output/out.json\"\n",
    "    \n",
    "    process_chat_to_training_data(chat_files, friend_ids, output_file)\n",
    "    \n",
    "    try:\n",
    "        with open(output_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            logger.info(\"前 3 筆訓練資料範例：\")\n",
    "            for i, sample in enumerate(data[:3]):\n",
    "                logger.info(f\"樣本 {i + 1}:\")\n",
    "                logger.info(f\"Prompt: {sample['prompt']}\")\n",
    "                logger.info(f\"Response: {sample['response']}\")\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"無法讀取輸出檔案，請檢查處理過程是否成功。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eefe79b-12fe-4404-b379-ac31444cb0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:46:06,908 - 正在初始化情感分類器（Erlangshen-Roberta-110M-Sentiment）...\n",
      "Device set to use cuda:0\n",
      "2025-03-28 15:46:07,990 - 正在初始化零樣本分類器...\n",
      "Device set to use cuda:0\n",
      "讀取聊天檔案:   0%|          | 0/1 [00:00<?, ?it/s]2025-03-28 15:46:09,862 - 成功讀取檔案: data/claire.txt\n",
      "讀取聊天檔案: 100%|██████████| 1/1 [00:00<00:00, 382.62it/s]\n",
      "解析聊天檔案:   0%|          | 0/1 [00:00<?, ?it/s]2025-03-28 15:46:09,870 - 開始解析聊天記錄 (User: 0, Friend: 2)...\n",
      "\n",
      "解析聊天行: 100%|██████████| 2014/2014 [00:00<00:00, 212201.77it/s]\n",
      "2025-03-28 15:46:09,885 - 解析完成，生成 116 組對話\n",
      "解析聊天檔案: 100%|██████████| 1/1 [00:00<00:00, 47.95it/s]\n",
      "2025-03-28 15:46:09,888 - 開始預計算 1499 條訊息的嵌入向量...\n",
      "2025-03-28 15:46:09,910 - Use pytorch device_name: cuda\n",
      "2025-03-28 15:46:09,911 - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large\n",
      "計算嵌入分片:   0%|          | 0/1 [00:00<?, ?it/s]2025-03-28 15:46:13,783 - 處理分片 1/1 on GPU 0\n",
      "計算嵌入分片: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n",
      "2025-03-28 15:46:16,527 - 嵌入計算完成\n",
      "2025-03-28 15:46:16,527 - 開始添加情緒標籤...\n",
      "2025-03-28 15:46:16,587 - 開始全批量情感分類...\n",
      "情感分類批次處理: 100%|██████████| 6/6 [00:02<00:00,  2.31it/s]\n",
      "組裝情感標籤: 100%|██████████| 116/116 [00:00<00:00, 25638.37it/s]\n",
      "2025-03-28 15:46:19,206 - 情感標籤添加完成\n",
      "2025-03-28 15:46:19,207 - 開始添加話題標籤...\n",
      "2025-03-28 15:46:19,223 - 開始全批量話題分類...\n",
      "話題分類批次處理: 100%|██████████| 6/6 [00:44<00:00,  7.44s/it]\n",
      "組裝話題標籤: 100%|██████████| 116/116 [00:00<00:00, 844.34it/s]\n",
      "2025-03-28 15:47:03,986 - 話題標籤添加完成\n",
      "2025-03-28 15:47:03,988 - 開始混合對話...\n",
      "混合對話: 100%|██████████| 1499/1499 [00:00<00:00, 887279.38it/s]\n",
      "2025-03-28 15:47:03,994 - 混合完成，生成 268 組對話\n",
      "2025-03-28 15:47:03,995 - 開始格式化訓練資料...\n",
      "2025-03-28 15:47:03,996 - 預先批量計算所有對話行為...\n",
      "2025-03-28 15:47:04,017 - 正在對 1499 條訊息進行對話行為分類，批次大小: 256\n",
      "行為分類批次處理: 100%|██████████| 6/6 [01:13<00:00, 12.26s/it]\n",
      "後處理對話行為: 100%|██████████| 1499/1499 [00:00<00:00, 14577.94it/s]\n",
      "格式化對話組: 100%|██████████| 268/268 [00:00<00:00, 4650.22it/s]\n",
      "2025-03-28 15:48:17,729 - 格式化完成，生成 1201 筆訓練資料\n",
      "2025-03-28 15:48:17,749 - 訓練資料已儲存至 output/out.json，總共 1201 筆資料\n",
      "2025-03-28 15:48:17,757 - 前 3 筆訓練資料範例：\n",
      "2025-03-28 15:48:17,757 - 樣本 1:\n",
      "2025-03-28 15:48:17,759 - Prompt: User0: 啊他到底有沒有女朋友 [情緒: 焦慮, 行為: 告別, 話題: 感情八卦]\n",
      "2025-03-28 15:48:17,760 - Response: 他顏值真的很高🥺🥺🥺 [情緒: 喜愛, 行為: None, 話題: 感情八卦]\n",
      "2025-03-28 15:48:17,762 - 樣本 2:\n",
      "2025-03-28 15:48:17,763 - Prompt: User0: 啊他到底有沒有女朋友 [情緒: 焦慮, 行為: 告別, 話題: 感情八卦]\n",
      "User0: 他顏值真的很高🥺🥺🥺 [情緒: 喜愛, 行為: None, 話題: 感情八卦]\n",
      "2025-03-28 15:48:17,764 - Response: 雖然我覺得 [情緒: 開心, 行為: None, 話題: 感情八卦]\n",
      "2025-03-28 15:48:17,765 - 樣本 3:\n",
      "2025-03-28 15:48:17,766 - Prompt: User0: 啊他到底有沒有女朋友 [情緒: 焦慮, 行為: 告別, 話題: 感情八卦]\n",
      "User0: 他顏值真的很高🥺🥺🥺 [情緒: 喜愛, 行為: None, 話題: 感情八卦]\n",
      "User0: 雖然我覺得 [情緒: 開心, 行為: None, 話題: 感情八卦]\n",
      "2025-03-28 15:48:17,768 - Response: 很冷淡 [情緒: 難過, 行為: 引入, 話題: 感情八卦]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import List, Tuple\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import logging\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import emoji\n",
    "import os\n",
    "import opencc\n",
    "\n",
    "# 設置記憶體管理環境變數\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# 設置日誌\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 初始化多 GPU 環境\n",
    "device_ids = [0, 1]  # 兩張 A10G\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 清理 GPU 記憶體\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 定義分類標籤\n",
    "act_labels = [\"提問\", \"補充\", \"引入\", \"表達情感\", \"讚美\", \"道歉\", \"感謝\", \"請求\", \"拒絕\", \"建議\", \"問候\", \"告別\", \"確認\", \"表達意圖\", \"吐槽\", \"催促\", \"安慰\", \"接梗\"]\n",
    "topic_labels = [\"活動\", \"感情\", \"學業\", \"娛樂\", \"人際\", \"課業壓力\", \"社團活動\", \"感情八卦\", \"生活瑣事\"]\n",
    "\n",
    "# 初始化簡繁轉換器\n",
    "converter_to_simplified = opencc.OpenCC('t2s')\n",
    "converter_to_traditional = opencc.OpenCC('s2t')\n",
    "\n",
    "# 動態批次大小\n",
    "def get_dynamic_batch_size(messages: List[str], base_batch_size: int = 256) -> int:\n",
    "    gpu_memory = torch.cuda.memory_reserved(device) / 1024**3\n",
    "    max_memory = 24  # A10G 24GB\n",
    "    if gpu_memory > max_memory * 0.8:\n",
    "        return max(16, base_batch_size // 2)\n",
    "    return base_batch_size\n",
    "\n",
    "# 單進程分片計算嵌入\n",
    "def compute_chunk(chunk: List[str], gpu_id: int, batch_size: int, embedder: SentenceTransformer) -> torch.Tensor:\n",
    "    torch.cuda.set_device(gpu_id)\n",
    "    embedder.to(f\"cuda:{gpu_id}\")\n",
    "    try:\n",
    "        embeddings = embedder.encode(chunk, convert_to_tensor=True, batch_size=batch_size, show_progress_bar=False)\n",
    "        embeddings = embeddings.to(\"cuda:0\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        return embeddings\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        logger.warning(f\"GPU {gpu_id} 記憶體不足，減半批次大小重試...\")\n",
    "        embeddings = embedder.encode(chunk, convert_to_tensor=True, batch_size=batch_size // 2, show_progress_bar=False)\n",
    "        embeddings = embeddings.to(\"cuda:0\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        return embeddings\n",
    "\n",
    "def precompute_embeddings(messages: List[str], num_gpus: int = 2, chunk_size: int = 5000) -> torch.Tensor:\n",
    "    logger.info(f\"開始預計算 {len(messages)} 條訊息的嵌入向量...\")\n",
    "    simplified_messages = [converter_to_simplified.convert(msg) for msg in messages]\n",
    "    chunks = [simplified_messages[i:i + chunk_size] for i in range(0, len(messages), chunk_size)]\n",
    "    batch_size = get_dynamic_batch_size(messages)\n",
    "    \n",
    "    embedder = SentenceTransformer('intfloat/multilingual-e5-large')\n",
    "    results = []\n",
    "    \n",
    "    for i, chunk in enumerate(tqdm(chunks, desc=\"計算嵌入分片\")):\n",
    "        gpu_id = device_ids[i % num_gpus]\n",
    "        logger.info(f\"處理分片 {i+1}/{len(chunks)} on GPU {gpu_id}\")\n",
    "        chunk_embeddings = compute_chunk(chunk, gpu_id, batch_size, embedder)\n",
    "        results.append(chunk_embeddings)\n",
    "    \n",
    "    embeddings = torch.cat(results, dim=0)\n",
    "    embeddings = embeddings.cpu()\n",
    "    logger.info(\"嵌入計算完成\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return embeddings\n",
    "\n",
    "# 清洗文本\n",
    "def clean_text(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    patterns = r'(上午|下午)\\d{1,2}:\\d{2}\\s*|\\[照片\\]|\\[影片\\]|\\[貼圖\\]|.*已收回訊息.*|☎.*|^\\*+$'\n",
    "    return re.sub(patterns, '', text).strip()\n",
    "\n",
    "# 關鍵詞分類（擴展行為與話題）\n",
    "def keyword_infer_dialogue_act(message: str, prev_act: str = None) -> str:\n",
    "    message_lower = message.lower()\n",
    "    keywords = {\n",
    "        \"提問\": ['有沒有', '什麼', '會不會', '你覺得呢', '怎麼', '為什麼', '嗎', '哪個', '可不可以', '到了沒', '幾點', '到底', '知道', '多少'],\n",
    "        \"補充\": ['因為', '所以', '雖然', '不過', '但是', '然後', '而且', '結果', '還有', '幫', '就'],\n",
    "        \"引入\": ['重點是', '主要是', '說到', '講到', '提到', '我也不知道'],\n",
    "        \"表達情感\": ['難過', '尷尬', '自豪', '麻煩', '緊張', '開心', '笑死', '希望', '怕', '覺得', '累了', '冷淡', '好笑', '靠北', '你娘', '超趕'],\n",
    "        \"讚美\": ['漂亮', '帥', '很棒', '很讚', '很可愛', '適合', '好會', '好一點', '顏值', '很高'],\n",
    "        \"道歉\": ['對不起', '抱歉', '不好意思', 'sorry'],\n",
    "        \"感謝\": ['謝謝', '感謝', '感激', '多謝'],\n",
    "        \"請求\": ['拜託', '請', '幫我', '可以嗎'],\n",
    "        \"拒絕\": ['不要', '不行', '不可以', '不ok', '沒辦法', '不會', '我沒'],\n",
    "        \"建議\": ['建議', '不如', '要不要', '不然', '等等再'],\n",
    "        \"問候\": ['嗨', '嘿', '你好', '早安'],\n",
    "        \"告別\": ['掰掰', '拜拜', '再見', '晚安', '解散', '出門', '你刪掉啊'],\n",
    "        \"確認\": ['真的假的', '確定', '確認', '好啦'],\n",
    "        \"表達意圖\": ['我要', '我想', '我會'],\n",
    "        \"吐槽\": ['笑死', '怎麼可能', '超醜', '靠腰', '你快點'],\n",
    "        \"催促\": ['快點', '最好快點', '趕緊', '供三信'],\n",
    "        \"安慰\": ['不會吧', '又沒差', '沒事的'],\n",
    "        \"接梗\": ['超好笑', '哈哈哈', '我也是吧', '後來也換']\n",
    "    }\n",
    "    for act, kws in keywords.items():\n",
    "        if any(kw in message_lower for kw in kws):\n",
    "            return act\n",
    "    return \"回答\" if prev_act == \"提問\" else None\n",
    "\n",
    "# 初始化分類器\n",
    "logger.info(\"正在初始化情感分類器（Erlangshen-Roberta-110M-Sentiment）...\")\n",
    "sentiment_classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"IDEA-CCNL/Erlangshen-Roberta-110M-Sentiment\",\n",
    "    device=device_ids[0],\n",
    "    truncation=True,\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "logger.info(\"正在初始化零樣本分類器...\")\n",
    "zero_shot_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\",\n",
    "    device=device_ids[0],\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "# 對話行為分類\n",
    "def infer_dialogue_act(messages: List[str], prev_acts: List[str] = None, embeddings: torch.Tensor = None) -> List[str]:\n",
    "    if prev_acts is None:\n",
    "        prev_acts = [None] * len(messages)\n",
    "    \n",
    "    simplified_messages = [converter_to_simplified.convert(msg) for msg in messages]\n",
    "    dataset = Dataset.from_dict({\"text\": simplified_messages})\n",
    "    batch_size = get_dynamic_batch_size(messages)\n",
    "    logger.info(f\"正在對 {len(messages)} 條訊息進行對話行為分類，批次大小: {batch_size}\")\n",
    "    \n",
    "    num_batches = (len(messages) + batch_size - 1) // batch_size\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(messages), batch_size), total=num_batches, desc=\"行為分類批次處理\"):\n",
    "        batch = simplified_messages[i:i + batch_size]\n",
    "        batch_results = zero_shot_classifier(batch, act_labels, multi_label=False, batch_size=len(batch))\n",
    "        results.extend(batch_results)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    predicted_acts = []\n",
    "    for i, (message, prev_act, result) in tqdm(enumerate(zip(messages, prev_acts, results)), total=len(messages), desc=\"後處理對話行為\"):\n",
    "        predicted_act = result['labels'][0]\n",
    "        confidence = result['scores'][0]\n",
    "        \n",
    "        if confidence < 0.1 and embeddings is not None and i > 0:  # 降低閾值至 0.1\n",
    "            similarity = util.cos_sim(embeddings[i], embeddings[i-1]).item()\n",
    "            if similarity > 0.7:\n",
    "                predicted_act = prev_acts[i-1]\n",
    "            else:\n",
    "                predicted_act = keyword_infer_dialogue_act(message, prev_act)\n",
    "        elif prev_act == \"提問\" and predicted_act not in [\"提問\", \"補充\", \"回答\"]:\n",
    "            predicted_act = \"回答\"\n",
    "        \n",
    "        predicted_acts.append(predicted_act)\n",
    "    return predicted_acts\n",
    "\n",
    "# 解析聊天記錄\n",
    "def parse_chat_log(chat_log: str, user_id: str, friend_id: str, time_threshold: int = 5) -> List[List[Tuple[str, str, int]]]:\n",
    "    lines = [line.strip() for line in chat_log.split('\\n') if line.strip() and \"儲存日期\" not in line and not re.match(r'\\d{4}/\\d{2}/\\d{2}', line)]\n",
    "    conversation_groups = []\n",
    "    current_group = []\n",
    "    prev_time = None\n",
    "    \n",
    "    logger.info(f\"開始解析聊天記錄 (User: {user_id}, Friend: {friend_id})...\")\n",
    "    for line in tqdm(lines, desc=\"解析聊天行\"):\n",
    "        match = re.match(r'(上午|下午)(\\d{1,2}):(\\d{2})\\s*([A-B])\\s+(.+)', line)\n",
    "        if match:\n",
    "            period, hour, minute, speaker, message = match.groups()\n",
    "            cleaned_message = clean_text(message)\n",
    "            if cleaned_message and len(cleaned_message) >= 3:\n",
    "                current_time = int(hour) * 60 + int(minute) + (12 * 60 if period == \"下午\" else 0)\n",
    "                if prev_time and abs(current_time - prev_time) > time_threshold:\n",
    "                    conversation_groups.append(current_group)\n",
    "                    current_group = []\n",
    "                role = f\"User{user_id}\" if speaker == \"B\" else f\"User{friend_id}\"\n",
    "                current_group.append((role, cleaned_message, current_time))\n",
    "                prev_time = current_time\n",
    "    \n",
    "    if current_group:\n",
    "        conversation_groups.append(current_group)\n",
    "    logger.info(f\"解析完成，生成 {len(conversation_groups)} 組對話\")\n",
    "    return conversation_groups\n",
    "\n",
    "# 添加情緒標籤\n",
    "def add_emotion_labels(conversation_groups: List[List[Tuple[str, str, int]]], embeddings: torch.Tensor) -> List[List[Tuple[str, str, int, str]]]:\n",
    "    all_messages = [emoji.demojize(msg) for group in conversation_groups for _, msg, _ in group]\n",
    "    simplified_messages = [converter_to_simplified.convert(msg) for msg in all_messages]\n",
    "    batch_size = get_dynamic_batch_size(all_messages)\n",
    "    logger.info(\"開始全批量情感分類...\")\n",
    "    dataset = Dataset.from_dict({\"text\": simplified_messages})\n",
    "    num_batches = (len(all_messages) + batch_size - 1) // batch_size\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(all_messages), batch_size), total=num_batches, desc=\"情感分類批次處理\"):\n",
    "        batch = simplified_messages[i:i + batch_size]\n",
    "        batch_results = sentiment_classifier(batch, batch_size=len(batch), truncation=True, max_length=128)\n",
    "        results.extend(batch_results)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    labeled_groups = [[] for _ in conversation_groups]\n",
    "    emotion_map = {\n",
    "        'Positive': '開心', 'Negative': '難過', 'Neutral': '中性',\n",
    "        ':smiling_face_with_heart-eyes:': '喜愛', ':pouting_face:': '難過',\n",
    "        ':laughing:': '開心', ':sob:': '難過', ':angry_face:': '憤怒',\n",
    "        ':face_with_tears_of_joy:': '開心', ':pleading_face:': '喜愛',\n",
    "        ':scream:': '興奮', ':thinking_face:': '焦慮', ':weary_face:': '無奈',\n",
    "        ':sleeping_face:': '懶散'\n",
    "    }\n",
    "    msg_idx = 0\n",
    "    for group_idx, group in enumerate(tqdm(conversation_groups, desc=\"組裝情感標籤\")):\n",
    "        for speaker, message, time in group:\n",
    "            sentiment = results[msg_idx]['label']\n",
    "            confidence = results[msg_idx]['score']\n",
    "            emotion = emotion_map.get(sentiment, '中性')\n",
    "            # 檢查表情符號\n",
    "            for emoji_key, emo in emotion_map.items():\n",
    "                if emoji_key in message and emo != '中性':\n",
    "                    emotion = emo\n",
    "                    break\n",
    "            # 降低閾值並增強上下文推理\n",
    "            if confidence < 0.5 and msg_idx > 0:\n",
    "                similarity = util.cos_sim(embeddings[msg_idx], embeddings[msg_idx-1]).item()\n",
    "                if similarity > 0.7:\n",
    "                    emotion = labeled_groups[group_idx][-1][3] if labeled_groups[group_idx] else '中性'\n",
    "            # 關鍵詞後處理\n",
    "            message_lower = message.lower()\n",
    "            if '笑死' in message_lower or '好笑' in message_lower or '哈哈' in message_lower:\n",
    "                emotion = '開心' if '超' not in message_lower else '興奮'\n",
    "            elif '難過' in message_lower or '尷尬' in message_lower or '怕' in message_lower or '冷淡' in message_lower:\n",
    "                emotion = '難過'\n",
    "            elif '很高' in message_lower and '顏值' in message_lower:\n",
    "                emotion = '喜愛'\n",
    "            elif '你娘' in message_lower or '靠北' in message_lower or '耖你媽' in message_lower:\n",
    "                emotion = '難過' if '笑' not in message_lower else '開心'\n",
    "            elif '怎麼辦' in message_lower or '到底' in message_lower or '超趕' in message_lower:\n",
    "                emotion = '焦慮'\n",
    "            elif '我要睡了' in message_lower or '又沒差' in message_lower:\n",
    "                emotion = '懶散'\n",
    "            elif '去宜蘭玩' in message_lower or '超好笑' in message_lower:\n",
    "                emotion = '興奮' if '超' in message_lower else '開心'\n",
    "            elif '我沒準備' in message_lower or '我他媽' in message_lower:\n",
    "                emotion = '焦慮' if '怎麼辦' in message_lower else '無奈'\n",
    "            labeled_groups[group_idx].append((speaker, message, time, emotion))\n",
    "            msg_idx += 1\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    logger.info(\"情感標籤添加完成\")\n",
    "    return labeled_groups\n",
    "\n",
    "# 添加話題標籤\n",
    "def add_topic_labels(conversation_groups: List[List[Tuple[str, str, int, str]]], embeddings: torch.Tensor) -> List[List[Tuple[str, str, int, str, str]]]:\n",
    "    all_messages = [msg for group in conversation_groups for _, msg, _, _ in group]\n",
    "    simplified_messages = [converter_to_simplified.convert(msg) for msg in all_messages]\n",
    "    batch_size = get_dynamic_batch_size(all_messages)\n",
    "    logger.info(\"開始全批量話題分類...\")\n",
    "    dataset = Dataset.from_dict({\"text\": simplified_messages})\n",
    "    num_batches = (len(all_messages) + batch_size - 1) // batch_size\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(all_messages), batch_size), total=num_batches, desc=\"話題分類批次處理\"):\n",
    "        batch = simplified_messages[i:i + batch_size]\n",
    "        batch_results = zero_shot_classifier(batch, topic_labels, multi_label=True, batch_size=len(batch))\n",
    "        results.extend(batch_results)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    labeled_groups = [[] for _ in conversation_groups]\n",
    "    msg_idx = 0\n",
    "    for group_idx, group in enumerate(tqdm(conversation_groups, desc=\"組裝話題標籤\")):\n",
    "        for speaker, message, time, emotion in group:\n",
    "            result = results[msg_idx]\n",
    "            predicted_topics = sorted([(label, score) for label, score in zip(result['labels'], result['scores'])], key=lambda x: x[1], reverse=True)[:3]\n",
    "            predicted_topics = [label for label, score in predicted_topics if score > 0.4]\n",
    "            # 關鍵詞後處理\n",
    "            message_lower = message.lower()\n",
    "            if '女朋友' in message_lower or '喜歡' in message_lower or '在一起' in message_lower:\n",
    "                predicted_topics.append('感情八卦')\n",
    "            if '群組' in message_lower or '男生' in message_lower or '女生' in message_lower or '室友' in message_lower:\n",
    "                predicted_topics.append('人際')\n",
    "            if '笑死' in message_lower or '好笑' in message_lower or '照片' in message_lower:\n",
    "                predicted_topics.append('娛樂')\n",
    "            if '遊覽車' in message_lower or '出去玩' in message_lower or '計畫' in message_lower or '股練' in message_lower:\n",
    "                predicted_topics.append('社團活動')\n",
    "            if '填' in message_lower or '名額' in message_lower or '家教' in message_lower:\n",
    "                predicted_topics.append('課業壓力')\n",
    "            if '睡了' in message_lower or '洗澡' in message_lower or '行李' in message_lower or '出門' in message_lower:\n",
    "                predicted_topics.append('生活瑣事')\n",
    "            if not predicted_topics and msg_idx > 0:\n",
    "                similarity = util.cos_sim(embeddings[msg_idx], embeddings[msg_idx-1]).item()\n",
    "                if similarity > 0.7:\n",
    "                    topic_str = labeled_groups[group_idx][-1][4] if labeled_groups[group_idx] else \"日常\"\n",
    "                else:\n",
    "                    topic_str = \"日常\"\n",
    "            else:\n",
    "                topic_str = \"+\".join(sorted(set(predicted_topics))) if predicted_topics else \"日常\"\n",
    "            labeled_groups[group_idx].append((speaker, message, time, emotion, topic_str))\n",
    "            msg_idx += 1\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    logger.info(\"話題標籤添加完成\")\n",
    "    return labeled_groups\n",
    "\n",
    "# 優化格式化訓練數據\n",
    "def format_training_data(conversation_groups: List[List[Tuple[str, str, int, str, str]]], embeddings: torch.Tensor, max_turns: int = 10, similarity_threshold: float = 0.8) -> List[dict]:\n",
    "    training_data = []\n",
    "    msg_idx = 0\n",
    "    \n",
    "    logger.info(\"開始格式化訓練資料...\")\n",
    "    all_messages = [item[1] for group in conversation_groups for item in group]\n",
    "    logger.info(\"預先批量計算所有對話行為...\")\n",
    "    all_dialogue_acts = infer_dialogue_act(all_messages, embeddings=embeddings)\n",
    "    act_idx = 0\n",
    "    \n",
    "    for group in tqdm(conversation_groups, desc=\"格式化對話組\"):\n",
    "        messages = [item[1] for item in group]\n",
    "        dialogue_acts = all_dialogue_acts[act_idx:act_idx + len(messages)]\n",
    "        act_idx += len(messages)\n",
    "        \n",
    "        if len(messages) > 1:\n",
    "            curr_embeddings = embeddings[msg_idx:msg_idx + len(messages) - 1]\n",
    "            next_embeddings = embeddings[msg_idx + 1:msg_idx + len(messages)]\n",
    "            similarities = util.cos_sim(curr_embeddings, next_embeddings).diagonal().cpu().numpy()\n",
    "        else:\n",
    "            similarities = np.array([])\n",
    "        \n",
    "        for i in range(len(group) - 1):\n",
    "            context = group[max(0, i - max_turns + 1):i + 1]\n",
    "            next_msg = group[i + 1]\n",
    "            similarity = similarities[i] if i < len(similarities) else 0.0\n",
    "            \n",
    "            if similarity >= similarity_threshold and len(next_msg[1]) >= 3:\n",
    "                prompt = \"\\n\".join(f\"{s}: {m} [情緒: {e}, 行為: {dialogue_acts[j]}, 話題: {t}]\" \n",
    "                                 for j, (s, m, _, e, t) in enumerate(context))\n",
    "                response = f\"{next_msg[1]} [情緒: {next_msg[3]}, 行為: {dialogue_acts[i + 1]}, 話題: {next_msg[4]}]\"\n",
    "                training_data.append({\"prompt\": prompt, \"response\": response})\n",
    "        msg_idx += len(group)\n",
    "    \n",
    "    logger.info(f\"格式化完成，生成 {len(training_data)} 筆訓練資料\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return training_data\n",
    "\n",
    "# 混合多人群聊\n",
    "def mix_conversations(chat_logs: List[str], friend_ids: List[str], time_threshold: int = 5, max_turns: int = 10, similarity_threshold: float = 0.8) -> List[dict]:\n",
    "    all_groups = []\n",
    "    for user_id, (chat_log, friend_id) in enumerate(tqdm(zip(chat_logs, friend_ids), desc=\"解析聊天檔案\", total=len(chat_logs))):\n",
    "        groups = parse_chat_log(chat_log, str(user_id), friend_id, time_threshold)\n",
    "        all_groups.extend(groups)\n",
    "    \n",
    "    all_messages = [msg for group in all_groups for _, msg, _ in group]\n",
    "    embeddings = precompute_embeddings(all_messages, num_gpus=2, chunk_size=5000)\n",
    "    \n",
    "    logger.info(\"開始添加情緒標籤...\")\n",
    "    all_groups = add_emotion_labels(all_groups, embeddings)\n",
    "    logger.info(\"開始添加話題標籤...\")\n",
    "    all_groups = add_topic_labels(all_groups, embeddings)\n",
    "    \n",
    "    logger.info(\"開始混合對話...\")\n",
    "    all_conversations = [item for group in all_groups for item in group]\n",
    "    all_conversations.sort(key=lambda x: x[2])\n",
    "    \n",
    "    mixed_groups = []\n",
    "    current_group = []\n",
    "    prev_time = None\n",
    "    prev_topic = None\n",
    "    for item in tqdm(all_conversations, desc=\"混合對話\"):\n",
    "        speaker, message, time, emotion, topic = item\n",
    "        if prev_time and (abs(time - prev_time) > time_threshold or topic.split(\"+\")[0] != prev_topic):\n",
    "            if current_group:\n",
    "                mixed_groups.append(current_group)\n",
    "            current_group = []\n",
    "        current_group.append((speaker, message, time, emotion, topic))\n",
    "        prev_time = time\n",
    "        prev_topic = topic.split(\"+\")[0]\n",
    "    if current_group:\n",
    "        mixed_groups.append(current_group)\n",
    "    \n",
    "    logger.info(f\"混合完成，生成 {len(mixed_groups)} 組對話\")\n",
    "    return format_training_data(mixed_groups, embeddings, max_turns, similarity_threshold)\n",
    "\n",
    "# 主函數\n",
    "def process_chat_to_training_data(chat_files: List[str], friend_ids: List[str], output_file: str, time_threshold: int = 5, max_turns: int = 10, similarity_threshold: float = 0.8):\n",
    "    chat_logs = []\n",
    "    for chat_file in tqdm(chat_files, desc=\"讀取聊天檔案\"):\n",
    "        try:\n",
    "            with open(chat_file, 'r', encoding='utf-8') as f:\n",
    "                chat_logs.append(f.read())\n",
    "            logger.info(f\"成功讀取檔案: {chat_file}\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"找不到檔案: {chat_file}\")\n",
    "            return\n",
    "    \n",
    "    training_data = mix_conversations(chat_logs, friend_ids, time_threshold, max_turns, similarity_threshold)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(training_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    logger.info(f\"訓練資料已儲存至 {output_file}，總共 {len(training_data)} 筆資料\")\n",
    "\n",
    "# 測試用\n",
    "if __name__ == \"__main__\":\n",
    "    chat_files = [\"data/claire.txt\"]\n",
    "    friend_ids = [\"2\"]\n",
    "    output_file = \"output/out.json\"\n",
    "    \n",
    "    process_chat_to_training_data(chat_files, friend_ids, output_file)\n",
    "    \n",
    "    try:\n",
    "        with open(output_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            logger.info(\"前 3 筆訓練資料範例：\")\n",
    "            for i, sample in enumerate(data[:3]):\n",
    "                logger.info(f\"樣本 {i + 1}:\")\n",
    "                logger.info(f\"Prompt: {sample['prompt']}\")\n",
    "                logger.info(f\"Response: {sample['response']}\")\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"無法讀取輸出檔案，請檢查處理過程是否成功。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd32b27-52da-4848-9083-63e5212cc61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 16:24:10,861 - 正在初始化情感分類器（Erlangshen-Roberta-110M-Sentiment）...\n",
      "Device set to use cuda:0\n",
      "2025-03-28 16:24:11,988 - 正在初始化零樣本分類器...\n",
      "Device set to use cuda:0\n",
      "讀取聊天檔案:   0%|          | 0/1 [00:00<?, ?it/s]2025-03-28 16:24:13,838 - 成功讀取檔案: data/claire.txt\n",
      "讀取聊天檔案: 100%|██████████| 1/1 [00:00<00:00, 170.59it/s]\n",
      "解析聊天檔案:   0%|          | 0/1 [00:00<?, ?it/s]2025-03-28 16:24:13,873 - 開始解析聊天記錄 (User: 0, Friend: 2)...\n",
      "\n",
      "解析聊天行:   0%|          | 0/26848 [00:00<?, ?it/s]\u001b[A\n",
      "解析聊天行: 100%|██████████| 26848/26848 [00:00<00:00, 211445.88it/s]\u001b[A\n",
      "2025-03-28 16:24:14,006 - 解析完成，生成 1253 組對話\n",
      "解析聊天檔案: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n",
      "2025-03-28 16:24:14,011 - 開始預計算 19809 條訊息的嵌入向量...\n",
      "2025-03-28 16:24:14,193 - Use pytorch device_name: cuda\n",
      "2025-03-28 16:24:14,194 - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large\n",
      "計算嵌入分片:   0%|          | 0/4 [00:00<?, ?it/s]2025-03-28 16:24:17,592 - 處理分片 1/4 on GPU 0\n",
      "計算嵌入分片:  25%|██▌       | 1/4 [00:04<00:12,  4.16s/it]2025-03-28 16:24:21,750 - 處理分片 2/4 on GPU 1\n",
      "計算嵌入分片:  50%|█████     | 2/4 [00:07<00:07,  3.82s/it]2025-03-28 16:24:25,332 - 處理分片 3/4 on GPU 0\n",
      "計算嵌入分片:  75%|███████▌  | 3/4 [00:10<00:03,  3.32s/it]2025-03-28 16:24:28,069 - 處理分片 4/4 on GPU 1\n",
      "計算嵌入分片: 100%|██████████| 4/4 [00:13<00:00,  3.25s/it]\n",
      "2025-03-28 16:24:30,625 - 嵌入計算完成\n",
      "2025-03-28 16:24:30,628 - 開始添加情緒標籤...\n",
      "2025-03-28 16:24:31,394 - 開始全批量情感分類...\n",
      "情感分類批次處理: 100%|██████████| 78/78 [00:27<00:00,  2.88it/s]\n",
      "組裝情感標籤: 100%|██████████| 1253/1253 [00:00<00:00, 4277.22it/s]\n",
      "2025-03-28 16:24:58,797 - 情感標籤添加完成\n",
      "2025-03-28 16:24:58,801 - 開始添加話題標籤...\n",
      "2025-03-28 16:24:58,975 - 開始全批量話題分類...\n",
      "話題分類批次處理: 100%|██████████| 78/78 [12:15<00:00,  9.42s/it]\n",
      "組裝話題標籤: 100%|██████████| 1253/1253 [00:02<00:00, 550.88it/s]\n",
      "2025-03-28 16:37:16,385 - 話題標籤添加完成\n",
      "2025-03-28 16:37:16,397 - 開始混合對話...\n",
      "混合對話: 100%|██████████| 19809/19809 [00:00<00:00, 909015.96it/s]\n",
      "2025-03-28 16:37:16,426 - 混合完成，生成 4999 組對話\n",
      "2025-03-28 16:37:16,428 - 開始格式化訓練資料...\n",
      "2025-03-28 16:37:16,430 - 預先批量計算所有對話行為...\n",
      "2025-03-28 16:37:16,613 - 正在對 19809 條訊息進行對話行為分類，批次大小: 256\n",
      "行為分類批次處理: 100%|██████████| 78/78 [14:57<00:00, 11.50s/it]\n",
      "後處理對話行為: 100%|██████████| 19809/19809 [00:01<00:00, 11292.24it/s]\n",
      "格式化對話組: 100%|██████████| 4999/4999 [00:00<00:00, 6905.99it/s]\n",
      "2025-03-28 16:52:16,208 - 格式化完成，生成 5130 筆訓練資料\n",
      "2025-03-28 16:52:16,552 - 訓練資料已儲存至 output/out.json，總共 5130 筆資料\n",
      "2025-03-28 16:52:16,620 - 前 3 筆訓練資料範例：\n",
      "2025-03-28 16:52:16,621 - 樣本 1:\n",
      "2025-03-28 16:52:16,621 - Prompt: User0: 重點是\n",
      "2025-03-28 16:52:16,623 - Response: 我沒有不想喝\n",
      "2025-03-28 16:52:16,624 - Metadata: {\"context\": [{\"speaker\": \"User0\", \"message\": \"重點是\", \"emotion\": \"中性\", \"act\": \"引入\", \"topic\": \"日常\"}], \"response\": {\"speaker\": \"User0\", \"message\": \"我沒有不想喝\", \"emotion\": \"懶散\", \"act\": \"拒絕\", \"topic\": \"日常\"}}\n",
      "2025-03-28 16:52:16,625 - 樣本 2:\n",
      "2025-03-28 16:52:16,626 - Prompt: User2: 但感覺那個時候也沒辦法全到\n",
      "User2: 我原本還很自豪\n",
      "User0: 所以覺得這樣出去很尷尬\n",
      "User0: 如果合併\n",
      "2025-03-28 16:52:16,627 - Response: 會不會\n",
      "2025-03-28 16:52:16,628 - Metadata: {\"context\": [{\"speaker\": \"User2\", \"message\": \"但感覺那個時候也沒辦法全到\", \"emotion\": \"開心\", \"act\": \"問候\", \"topic\": \"日常\"}, {\"speaker\": \"User2\", \"message\": \"我原本還很自豪\", \"emotion\": \"開心\", \"act\": \"引入\", \"topic\": \"日常\"}, {\"speaker\": \"User0\", \"message\": \"所以覺得這樣出去很尷尬\", \"emotion\": \"難過\", \"act\": \"補充\", \"topic\": \"日常\"}, {\"speaker\": \"User0\", \"message\": \"如果合併\", \"emotion\": \"中性\", \"act\": \"閒聊\", \"topic\": \"日常\"}], \"response\": {\"speaker\": \"User0\", \"message\": \"會不會\", \"emotion\": \"中性\", \"act\": \"提問\", \"topic\": \"日常\"}}\n",
      "2025-03-28 16:52:16,630 - 樣本 3:\n",
      "2025-03-28 16:52:16,631 - Prompt: User2: 但感覺那個時候也沒辦法全到\n",
      "User2: 我原本還很自豪\n",
      "User0: 所以覺得這樣出去很尷尬\n",
      "User0: 如果合併\n",
      "User0: 會不會\n",
      "2025-03-28 16:52:16,632 - Response: 好一點\n",
      "2025-03-28 16:52:16,633 - Metadata: {\"context\": [{\"speaker\": \"User2\", \"message\": \"但感覺那個時候也沒辦法全到\", \"emotion\": \"開心\", \"act\": \"問候\", \"topic\": \"日常\"}, {\"speaker\": \"User2\", \"message\": \"我原本還很自豪\", \"emotion\": \"開心\", \"act\": \"引入\", \"topic\": \"日常\"}, {\"speaker\": \"User0\", \"message\": \"所以覺得這樣出去很尷尬\", \"emotion\": \"難過\", \"act\": \"補充\", \"topic\": \"日常\"}, {\"speaker\": \"User0\", \"message\": \"如果合併\", \"emotion\": \"中性\", \"act\": \"閒聊\", \"topic\": \"日常\"}, {\"speaker\": \"User0\", \"message\": \"會不會\", \"emotion\": \"中性\", \"act\": \"提問\", \"topic\": \"日常\"}], \"response\": {\"speaker\": \"User0\", \"message\": \"好一點\", \"emotion\": \"中性\", \"act\": \"讚美\", \"topic\": \"日常\"}}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import List, Tuple\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import logging\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import emoji\n",
    "import os\n",
    "import opencc\n",
    "\n",
    "# 設置記憶體管理環境變數\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# 設置日誌\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 初始化多 GPU 環境\n",
    "device_ids = [0, 1]  # 兩張 A10G\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 清理 GPU 記憶體\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 定義分類標籤\n",
    "act_labels = [\"提問\", \"補充\", \"引入\", \"表達情感\", \"讚美\", \"道歉\", \"感謝\", \"請求\", \"拒絕\", \"建議\", \"問候\", \"告別\", \"確認\", \"表達意圖\", \"吐槽\", \"催促\", \"安慰\", \"接梗\"]\n",
    "topic_labels = [\"活動\", \"感情\", \"學業\", \"娛樂\", \"人際\", \"課業壓力\", \"社團活動\", \"感情八卦\", \"生活瑣事\", \"宿舍生活\", \"考試\", \"旅行\", \"美食\", \"科技\"]\n",
    "\n",
    "# 初始化簡繁轉換器\n",
    "converter_to_simplified = opencc.OpenCC('t2s')\n",
    "converter_to_traditional = opencc.OpenCC('s2t')\n",
    "\n",
    "# 動態批次大小\n",
    "def get_dynamic_batch_size(messages: List[str], base_batch_size: int = 256) -> int:\n",
    "    gpu_memory = torch.cuda.memory_reserved(device) / 1024**3\n",
    "    max_memory = 24  # A10G 24GB\n",
    "    if gpu_memory > max_memory * 0.8:\n",
    "        return max(16, base_batch_size // 2)\n",
    "    return base_batch_size\n",
    "\n",
    "# 單進程分片計算嵌入\n",
    "def compute_chunk(chunk: List[str], gpu_id: int, batch_size: int, embedder: SentenceTransformer) -> torch.Tensor:\n",
    "    torch.cuda.set_device(gpu_id)\n",
    "    embedder.to(f\"cuda:{gpu_id}\")\n",
    "    try:\n",
    "        embeddings = embedder.encode(chunk, convert_to_tensor=True, batch_size=batch_size, show_progress_bar=False)\n",
    "        embeddings = embeddings.to(\"cuda:0\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        return embeddings\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        logger.warning(f\"GPU {gpu_id} 記憶體不足，減半批次大小重試...\")\n",
    "        embeddings = embedder.encode(chunk, convert_to_tensor=True, batch_size=batch_size // 2, show_progress_bar=False)\n",
    "        embeddings = embeddings.to(\"cuda:0\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        return embeddings\n",
    "\n",
    "def precompute_embeddings(messages: List[str], num_gpus: int = 2, chunk_size: int = 5000) -> torch.Tensor:\n",
    "    logger.info(f\"開始預計算 {len(messages)} 條訊息的嵌入向量...\")\n",
    "    simplified_messages = [converter_to_simplified.convert(msg) for msg in messages]\n",
    "    chunks = [simplified_messages[i:i + chunk_size] for i in range(0, len(messages), chunk_size)]\n",
    "    batch_size = get_dynamic_batch_size(messages)\n",
    "    \n",
    "    embedder = SentenceTransformer('intfloat/multilingual-e5-large')\n",
    "    results = []\n",
    "    \n",
    "    for i, chunk in enumerate(tqdm(chunks, desc=\"計算嵌入分片\")):\n",
    "        gpu_id = device_ids[i % num_gpus]\n",
    "        logger.info(f\"處理分片 {i+1}/{len(chunks)} on GPU {gpu_id}\")\n",
    "        chunk_embeddings = compute_chunk(chunk, gpu_id, batch_size, embedder)\n",
    "        results.append(chunk_embeddings)\n",
    "    \n",
    "    embeddings = torch.cat(results, dim=0)\n",
    "    embeddings = embeddings.cpu()\n",
    "    logger.info(\"嵌入計算完成\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return embeddings\n",
    "\n",
    "# 清洗文本\n",
    "def clean_text(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    patterns = r'(上午|下午)\\d{1,2}:\\d{2}\\s*|\\[照片\\]|\\[影片\\]|\\[貼圖\\]|.*已收回訊息.*|☎.*|^\\*+$'\n",
    "    return re.sub(patterns, '', text).strip()\n",
    "\n",
    "# 關鍵詞分類（優化行為標籤）\n",
    "def keyword_infer_dialogue_act(message: str, prev_act: str = None) -> str:\n",
    "    message_lower = message.lower()\n",
    "    keywords = {\n",
    "        \"提問\": ['有沒有', '什麼', '會不會', '你覺得呢', '怎麼', '為什麼', '嗎', '哪個', '可不可以', '到了沒', '幾點', '到底', '知道', '多少'],\n",
    "        \"補充\": ['因為', '所以', '雖然', '不過', '但是', '然後', '而且', '結果', '還有', '幫', '就', '剛剛'],\n",
    "        \"引入\": ['重點是', '主要是', '說到', '講到', '提到', '我也不知道'],\n",
    "        \"表達情感\": ['難過', '尷尬', '自豪', '麻煩', '緊張', '開心', '笑死', '希望', '怕', '覺得', '累了', '冷淡', '好笑', '靠北', '你娘', '超趕'],\n",
    "        \"讚美\": ['漂亮', '帥', '很棒', '很讚', '很可愛', '適合', '好會', '好一點', '顏值', '很高'],\n",
    "        \"道歉\": ['對不起', '抱歉', '不好意思', 'sorry'],\n",
    "        \"感謝\": ['謝謝', '感謝', '感激', '多謝'],\n",
    "        \"請求\": ['拜託', '請', '幫我', '可以嗎'],\n",
    "        \"拒絕\": ['不要', '不行', '不可以', '不ok', '沒辦法', '不會', '我沒'],\n",
    "        \"建議\": ['建議', '不如', '要不要', '不然', '等等再', '你可以'],\n",
    "        \"問候\": ['嗨', '嘿', '你好', '早安'],\n",
    "        \"告別\": ['掰掰', '拜拜', '再見', '晚安', '解散', '出門', '你刪掉啊'],\n",
    "        \"確認\": ['真的假的', '確定', '確認', '好啦'],\n",
    "        \"表達意圖\": ['我要', '我想', '我會'],\n",
    "        \"吐槽\": ['笑死', '怎麼可能', '超醜', '靠腰', '你快點'],\n",
    "        \"催促\": ['快點', '最好快點', '趕緊', '供三信'],\n",
    "        \"安慰\": ['不會吧', '又沒差', '沒事的'],\n",
    "        \"接梗\": ['超好笑', '哈哈哈', '我也是吧', '後來也換']\n",
    "    }\n",
    "    for act, kws in keywords.items():\n",
    "        if any(kw in message_lower for kw in kws):\n",
    "            return act\n",
    "    # 根據上下文調整\n",
    "    if prev_act == \"提問\" and '嗎' not in message_lower:\n",
    "        return \"回答\"\n",
    "    if '覺得' in message_lower or '很' in message_lower:\n",
    "        return \"表達情感\"\n",
    "    if '真的' in message_lower and '假的' in message_lower:\n",
    "        return \"確認\"\n",
    "    return \"閒聊\"  # 默認行為\n",
    "\n",
    "# 初始化分類器\n",
    "logger.info(\"正在初始化情感分類器（Erlangshen-Roberta-110M-Sentiment）...\")\n",
    "sentiment_classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"IDEA-CCNL/Erlangshen-Roberta-110M-Sentiment\",\n",
    "    device=device_ids[0],\n",
    "    truncation=True,\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "logger.info(\"正在初始化零樣本分類器...\")\n",
    "zero_shot_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\",\n",
    "    device=device_ids[0],\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "# 對話行為分類\n",
    "def infer_dialogue_act(messages: List[str], prev_acts: List[str] = None, embeddings: torch.Tensor = None) -> List[str]:\n",
    "    if prev_acts is None:\n",
    "        prev_acts = [None] * len(messages)\n",
    "    \n",
    "    simplified_messages = [converter_to_simplified.convert(msg) for msg in messages]\n",
    "    dataset = Dataset.from_dict({\"text\": simplified_messages})\n",
    "    batch_size = get_dynamic_batch_size(messages)\n",
    "    logger.info(f\"正在對 {len(messages)} 條訊息進行對話行為分類，批次大小: {batch_size}\")\n",
    "    \n",
    "    num_batches = (len(messages) + batch_size - 1) // batch_size\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(messages), batch_size), total=num_batches, desc=\"行為分類批次處理\"):\n",
    "        batch = simplified_messages[i:i + batch_size]\n",
    "        batch_results = zero_shot_classifier(batch, act_labels, multi_label=False, batch_size=len(batch))\n",
    "        results.extend(batch_results)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    predicted_acts = []\n",
    "    for i, (message, prev_act, result) in tqdm(enumerate(zip(messages, prev_acts, results)), total=len(messages), desc=\"後處理對話行為\"):\n",
    "        predicted_act = result['labels'][0]\n",
    "        confidence = result['scores'][0]\n",
    "        \n",
    "        if confidence < 0.1 and embeddings is not None and i > 0:\n",
    "            similarity = util.cos_sim(embeddings[i], embeddings[i-1]).item()\n",
    "            if similarity > 0.7 and prev_acts[i-1]:\n",
    "                predicted_act = prev_acts[i-1]\n",
    "            else:\n",
    "                predicted_act = keyword_infer_dialogue_act(message, prev_act)\n",
    "        elif prev_act == \"提問\" and predicted_act not in [\"提問\", \"補充\", \"回答\"]:\n",
    "            predicted_act = \"回答\"\n",
    "        \n",
    "        if not predicted_act:\n",
    "            predicted_act = \"閒聊\"\n",
    "        \n",
    "        predicted_acts.append(predicted_act)\n",
    "    return predicted_acts\n",
    "\n",
    "# 解析聊天記錄\n",
    "def parse_chat_log(chat_log: str, user_id: str, friend_id: str, time_threshold: int = 10) -> List[List[Tuple[str, str, int]]]:\n",
    "    lines = [line.strip() for line in chat_log.split('\\n') if line.strip() and \"儲存日期\" not in line and not re.match(r'\\d{4}/\\d{2}/\\d{2}', line)]\n",
    "    conversation_groups = []\n",
    "    current_group = []\n",
    "    prev_time = None\n",
    "    \n",
    "    logger.info(f\"開始解析聊天記錄 (User: {user_id}, Friend: {friend_id})...\")\n",
    "    for line in tqdm(lines, desc=\"解析聊天行\"):\n",
    "        match = re.match(r'(上午|下午)(\\d{1,2}):(\\d{2})\\s*([A-B])\\s+(.+)', line)\n",
    "        if match:\n",
    "            period, hour, minute, speaker, message = match.groups()\n",
    "            cleaned_message = clean_text(message)\n",
    "            if cleaned_message and len(cleaned_message) >= 3:\n",
    "                current_time = int(hour) * 60 + int(minute) + (12 * 60 if period == \"下午\" else 0)\n",
    "                if prev_time and abs(current_time - prev_time) > time_threshold:\n",
    "                    conversation_groups.append(current_group)\n",
    "                    current_group = []\n",
    "                role = f\"User{user_id}\" if speaker == \"B\" else f\"User{friend_id}\"\n",
    "                current_group.append((role, cleaned_message, current_time))\n",
    "                prev_time = current_time\n",
    "    \n",
    "    if current_group:\n",
    "        conversation_groups.append(current_group)\n",
    "    logger.info(f\"解析完成，生成 {len(conversation_groups)} 組對話\")\n",
    "    return conversation_groups\n",
    "\n",
    "# 添加情緒標籤（優化）\n",
    "def add_emotion_labels(conversation_groups: List[List[Tuple[str, str, int]]], embeddings: torch.Tensor) -> List[List[Tuple[str, str, int, str]]]:\n",
    "    all_messages = [emoji.demojize(msg) for group in conversation_groups for _, msg, _ in group]\n",
    "    simplified_messages = [converter_to_simplified.convert(msg) for msg in all_messages]\n",
    "    batch_size = get_dynamic_batch_size(all_messages)\n",
    "    logger.info(\"開始全批量情感分類...\")\n",
    "    dataset = Dataset.from_dict({\"text\": simplified_messages})\n",
    "    num_batches = (len(all_messages) + batch_size - 1) // batch_size\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(all_messages), batch_size), total=num_batches, desc=\"情感分類批次處理\"):\n",
    "        batch = simplified_messages[i:i + batch_size]\n",
    "        batch_results = sentiment_classifier(batch, batch_size=len(batch), truncation=True, max_length=128)\n",
    "        results.extend(batch_results)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    labeled_groups = [[] for _ in conversation_groups]\n",
    "    emotion_map = {\n",
    "        'Positive': '開心', 'Negative': '難過', 'Neutral': '中性',\n",
    "        ':smiling_face_with_heart-eyes:': '喜愛', ':pouting_face:': '難過',\n",
    "        ':laughing:': '開心', ':sob:': '難過', ':angry_face:': '憤怒',\n",
    "        ':face_with_tears_of_joy:': '開心', ':pleading_face:': '喜愛',\n",
    "        ':scream:': '興奮', ':thinking_face:': '焦慮', ':weary_face:': '無奈',\n",
    "        ':sleeping_face:': '懶散'\n",
    "    }\n",
    "    msg_idx = 0\n",
    "    for group_idx, group in enumerate(tqdm(conversation_groups, desc=\"組裝情感標籤\")):\n",
    "        for speaker, message, time in group:\n",
    "            sentiment = results[msg_idx]['label']\n",
    "            confidence = results[msg_idx]['score']\n",
    "            emotion = emotion_map.get(sentiment, '中性')\n",
    "            # 檢查表情符號\n",
    "            for emoji_key, emo in emotion_map.items():\n",
    "                if emoji_key in message and emo != '中性':\n",
    "                    emotion = emo\n",
    "                    break\n",
    "            # 增強上下文推理\n",
    "            if confidence < 0.6 and msg_idx > 0:\n",
    "                similarity = util.cos_sim(embeddings[msg_idx], embeddings[msg_idx-1]).item()\n",
    "                if similarity > 0.75 and labeled_groups[group_idx]:\n",
    "                    prev_emotion = labeled_groups[group_idx][-1][3]\n",
    "                    if prev_emotion in ['開心', '興奮', '喜愛'] and '愛' in message_lower:\n",
    "                        emotion = '喜愛'\n",
    "                    elif prev_emotion in ['難過', '焦慮', '無奈'] and '不' in message_lower:\n",
    "                        emotion = '難過'\n",
    "                    else:\n",
    "                        emotion = prev_emotion\n",
    "                elif '嗎' in message or '什麼' in message or '怎麼' in message:\n",
    "                    emotion = '焦慮'\n",
    "            # 更細化的關鍵詞後處理\n",
    "            message_lower = message.lower()\n",
    "            if '笑死' in message_lower or '好笑' in message_lower or '哈哈' in message_lower:\n",
    "                emotion = '開心' if '超' not in message_lower else '興奮'\n",
    "            elif '難過' in message_lower or '尷尬' in message_lower or '怕' in message_lower:\n",
    "                emotion = '難過'\n",
    "            elif '很高' in message_lower and '顏值' in message_lower:\n",
    "                emotion = '喜愛'\n",
    "            elif '你娘' in message_lower or '靠北' in message_lower or '耖你媽' in message_lower:\n",
    "                emotion = '難過' if '笑' not in message_lower else '開心'\n",
    "            elif '怎麼辦' in message_lower or '到底' in message_lower or '超趕' in message_lower:\n",
    "                emotion = '焦慮'\n",
    "            elif '我要睡了' in message_lower or '又沒差' in message_lower or '我沒' in message_lower:\n",
    "                emotion = '懶散'\n",
    "            elif '去宜蘭玩' in message_lower or '超好笑' in message_lower:\n",
    "                emotion = '興奮' if '超' in message_lower else '開心'\n",
    "            elif '我沒準備' in message_lower or '我他媽' in message_lower:\n",
    "                emotion = '焦慮' if '怎麼辦' in message_lower else '無奈'\n",
    "            elif '希望' in message_lower or '覺得' in message_lower and '不' not in message_lower:\n",
    "                emotion = '開心'\n",
    "            elif '愛' in message_lower or '喜歡' in message_lower:\n",
    "                emotion = '喜愛'\n",
    "            elif len(message) < 5 and '我' not in message_lower:\n",
    "                emotion = '中性'\n",
    "            labeled_groups[group_idx].append((speaker, message, time, emotion))\n",
    "            msg_idx += 1\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    logger.info(\"情感標籤添加完成\")\n",
    "    return labeled_groups\n",
    "\n",
    "# 添加話題標籤（優化）\n",
    "def add_topic_labels(conversation_groups: List[List[Tuple[str, str, int, str]]], embeddings: torch.Tensor) -> List[List[Tuple[str, str, int, str, str]]]:\n",
    "    all_messages = [msg for group in conversation_groups for _, msg, _, _ in group]\n",
    "    simplified_messages = [converter_to_simplified.convert(msg) for msg in all_messages]\n",
    "    batch_size = get_dynamic_batch_size(all_messages)\n",
    "    logger.info(\"開始全批量話題分類...\")\n",
    "    dataset = Dataset.from_dict({\"text\": simplified_messages})\n",
    "    num_batches = (len(all_messages) + batch_size - 1) // batch_size\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(all_messages), batch_size), total=num_batches, desc=\"話題分類批次處理\"):\n",
    "        batch = simplified_messages[i:i + batch_size]\n",
    "        batch_results = zero_shot_classifier(batch, topic_labels, multi_label=True, batch_size=len(batch))\n",
    "        results.extend(batch_results)\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    labeled_groups = [[] for _ in conversation_groups]\n",
    "    msg_idx = 0\n",
    "    for group_idx, group in enumerate(tqdm(conversation_groups, desc=\"組裝話題標籤\")):\n",
    "        for speaker, message, time, emotion in group:\n",
    "            result = results[msg_idx]\n",
    "            predicted_topics = sorted([(label, score) for label, score in zip(result['labels'], result['scores'])], key=lambda x: x[1], reverse=True)[:3]\n",
    "            predicted_topics = [label for label, score in predicted_topics if score > 0.3]\n",
    "            # 關鍵詞後處理\n",
    "            message_lower = message.lower()\n",
    "            if '女朋友' in message_lower or '喜歡' in message_lower or '在一起' in message_lower or '害羞' in message_lower:\n",
    "                predicted_topics.append('感情八卦')\n",
    "            if '群組' in message_lower or '男生' in message_lower or '女生' in message_lower or '室友' in message_lower or '合拍' in message_lower:\n",
    "                predicted_topics.append('人際')\n",
    "            if '笑死' in message_lower or '好笑' in message_lower or '照片' in message_lower:\n",
    "                predicted_topics.append('娛樂')\n",
    "            if '遊覽車' in message_lower or '出去玩' in message_lower or '計畫' in message_lower or '溜冰' in message_lower:\n",
    "                predicted_topics.append('社團活動')\n",
    "            if '填' in message_lower or '名額' in message_lower or '家教' in message_lower or '討論完' in message_lower:\n",
    "                predicted_topics.append('課業壓力')\n",
    "            if '睡了' in message_lower or '洗澡' in message_lower or '行李' in message_lower or '出門' in message_lower:\n",
    "                predicted_topics.append('生活瑣事')\n",
    "            if '宿舍' in message_lower or '床' in message_lower or '吵' in message_lower:\n",
    "                predicted_topics.append('宿舍生活')\n",
    "            if '考試' in message_lower or '成績' in message_lower or '期末' in message_lower:\n",
    "                predicted_topics.append('考試')\n",
    "            if '宜蘭' in message_lower or '台中' in message_lower or '旅行' in message_lower:\n",
    "                predicted_topics.append('旅行')\n",
    "            if '吃' in message_lower or '好吃' in message_lower or '餐廳' in message_lower:\n",
    "                predicted_topics.append('美食')\n",
    "            if '手機' in message_lower or '電腦' in message_lower or 'app' in message_lower or '帳號' in message_lower:\n",
    "                predicted_topics.append('科技')\n",
    "            # 上下文一致性檢查\n",
    "            if msg_idx > 0:\n",
    "                similarity = util.cos_sim(embeddings[msg_idx], embeddings[msg_idx-1]).item()\n",
    "                if similarity > 0.75 and labeled_groups[group_idx]:\n",
    "                    prev_topic = labeled_groups[group_idx][-1][4].split(\"+\")[0]\n",
    "                    if prev_topic in predicted_topics or not predicted_topics:\n",
    "                        topic_str = prev_topic\n",
    "                    else:\n",
    "                        topic_str = \"+\".join(sorted(set(predicted_topics))) if predicted_topics else \"日常\"\n",
    "                else:\n",
    "                    topic_str = \"+\".join(sorted(set(predicted_topics))) if predicted_topics else \"日常\"\n",
    "            else:\n",
    "                topic_str = \"+\".join(sorted(set(predicted_topics))) if predicted_topics else \"日常\"\n",
    "            labeled_groups[group_idx].append((speaker, message, time, emotion, topic_str))\n",
    "            msg_idx += 1\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    logger.info(\"話題標籤添加完成\")\n",
    "    return labeled_groups\n",
    "\n",
    "# 優化格式化訓練數據\n",
    "def format_training_data(conversation_groups: List[List[Tuple[str, str, int, str, str]]], embeddings: torch.Tensor, max_turns: int = 5, similarity_threshold: float = 0.85) -> List[dict]:\n",
    "    training_data = []\n",
    "    msg_idx = 0\n",
    "    \n",
    "    logger.info(\"開始格式化訓練資料...\")\n",
    "    all_messages = [item[1] for group in conversation_groups for item in group]\n",
    "    logger.info(\"預先批量計算所有對話行為...\")\n",
    "    all_dialogue_acts = infer_dialogue_act(all_messages, embeddings=embeddings)\n",
    "    act_idx = 0\n",
    "    \n",
    "    for group in tqdm(conversation_groups, desc=\"格式化對話組\"):\n",
    "        messages = [item[1] for item in group]\n",
    "        dialogue_acts = all_dialogue_acts[act_idx:act_idx + len(messages)]\n",
    "        act_idx += len(messages)\n",
    "        \n",
    "        if len(messages) > 1:\n",
    "            curr_embeddings = embeddings[msg_idx:msg_idx + len(messages) - 1]\n",
    "            next_embeddings = embeddings[msg_idx + 1:msg_idx + len(messages)]\n",
    "            similarities = util.cos_sim(curr_embeddings, next_embeddings).diagonal().cpu().numpy()\n",
    "        else:\n",
    "            similarities = np.array([])\n",
    "        \n",
    "        for i in range(len(group) - 1):\n",
    "            context = group[max(0, i - max_turns + 1):i + 1]\n",
    "            next_msg = group[i + 1]\n",
    "            similarity = similarities[i] if i < len(similarities) else 0.0\n",
    "            \n",
    "            if similarity >= similarity_threshold and len(next_msg[1]) >= 3:\n",
    "                prompt_text = \"\\n\".join(f\"{s}: {m}\" for s, m, _, _, _ in context)\n",
    "                response_text = next_msg[1]\n",
    "                metadata = {\n",
    "                    \"context\": [{\"speaker\": s, \"message\": m, \"emotion\": e, \"act\": dialogue_acts[j], \"topic\": t} \n",
    "                                for j, (s, m, _, e, t) in enumerate(context)],\n",
    "                    \"response\": {\"speaker\": next_msg[0], \"message\": next_msg[1], \"emotion\": next_msg[3], \n",
    "                                \"act\": dialogue_acts[i + 1], \"topic\": next_msg[4]}\n",
    "                }\n",
    "                training_data.append({\"prompt\": prompt_text, \"response\": response_text, \"metadata\": metadata})\n",
    "        msg_idx += len(group)\n",
    "    \n",
    "    logger.info(f\"格式化完成，生成 {len(training_data)} 筆訓練資料\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return training_data\n",
    "\n",
    "# 混合多人群聊\n",
    "def mix_conversations(chat_logs: List[str], friend_ids: List[str], time_threshold: int = 10, max_turns: int = 5, similarity_threshold: float = 0.85) -> List[dict]:\n",
    "    all_groups = []\n",
    "    for user_id, (chat_log, friend_id) in enumerate(tqdm(zip(chat_logs, friend_ids), desc=\"解析聊天檔案\", total=len(chat_logs))):\n",
    "        groups = parse_chat_log(chat_log, str(user_id), friend_id, time_threshold)\n",
    "        all_groups.extend(groups)\n",
    "    \n",
    "    all_messages = [msg for group in all_groups for _, msg, _ in group]\n",
    "    embeddings = precompute_embeddings(all_messages, num_gpus=2, chunk_size=5000)\n",
    "    \n",
    "    logger.info(\"開始添加情緒標籤...\")\n",
    "    all_groups = add_emotion_labels(all_groups, embeddings)\n",
    "    logger.info(\"開始添加話題標籤...\")\n",
    "    all_groups = add_topic_labels(all_groups, embeddings)\n",
    "    \n",
    "    logger.info(\"開始混合對話...\")\n",
    "    all_conversations = [item for group in all_groups for item in group]\n",
    "    all_conversations.sort(key=lambda x: x[2])\n",
    "    \n",
    "    mixed_groups = []\n",
    "    current_group = []\n",
    "    prev_time = None\n",
    "    prev_topic = None\n",
    "    for item in tqdm(all_conversations, desc=\"混合對話\"):\n",
    "        speaker, message, time, emotion, topic = item\n",
    "        if prev_time and (abs(time - prev_time) > time_threshold or topic.split(\"+\")[0] != prev_topic):\n",
    "            if current_group:\n",
    "                mixed_groups.append(current_group)\n",
    "            current_group = []\n",
    "        current_group.append((speaker, message, time, emotion, topic))\n",
    "        prev_time = time\n",
    "        prev_topic = topic.split(\"+\")[0]\n",
    "    if current_group:\n",
    "        mixed_groups.append(current_group)\n",
    "    \n",
    "    logger.info(f\"混合完成，生成 {len(mixed_groups)} 組對話\")\n",
    "    return format_training_data(mixed_groups, embeddings, max_turns, similarity_threshold)\n",
    "\n",
    "# 主函數\n",
    "def process_chat_to_training_data(chat_files: List[str], friend_ids: List[str], output_file: str, time_threshold: int = 10, max_turns: int = 5, similarity_threshold: float = 0.85):\n",
    "    chat_logs = []\n",
    "    for chat_file in tqdm(chat_files, desc=\"讀取聊天檔案\"):\n",
    "        try:\n",
    "            with open(chat_file, 'r', encoding='utf-8') as f:\n",
    "                chat_logs.append(f.read())\n",
    "            logger.info(f\"成功讀取檔案: {chat_file}\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"找不到檔案: {chat_file}\")\n",
    "            return\n",
    "    \n",
    "    training_data = mix_conversations(chat_logs, friend_ids, time_threshold, max_turns, similarity_threshold)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(training_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    logger.info(f\"訓練資料已儲存至 {output_file}，總共 {len(training_data)} 筆資料\")\n",
    "\n",
    "# 測試用\n",
    "if __name__ == \"__main__\":\n",
    "    chat_files = [\"data/claire.txt\"]\n",
    "    friend_ids = [\"2\"]\n",
    "    output_file = \"output/out.json\"\n",
    "    \n",
    "    process_chat_to_training_data(chat_files, friend_ids, output_file)\n",
    "    \n",
    "    try:\n",
    "        with open(output_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            logger.info(\"前 3 筆訓練資料範例：\")\n",
    "            for i, sample in enumerate(data[:3]):\n",
    "                logger.info(f\"樣本 {i + 1}:\")\n",
    "                logger.info(f\"Prompt: {sample['prompt']}\")\n",
    "                logger.info(f\"Response: {sample['response']}\")\n",
    "                logger.info(f\"Metadata: {json.dumps(sample['metadata'], ensure_ascii=False)}\")\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"無法讀取輸出檔案，請檢查處理過程是否成功。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19a5f3-dde4-49e2-9b71-e5db478d6921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
