#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¶…å¿«é€Ÿç‰ˆ MCP Server - ç›®æ¨™ 2-5 ç§’å…§å›æ‡‰
ä½¿ç”¨ gemini-2.0-flash-exp å’Œæœ€å°åŒ–ä¸Šä¸‹æ–‡
"""

import os
import json
import subprocess
import logging
from pathlib import Path
from typing import Dict, Optional, Any
from datetime import datetime
import asyncio
import uvloop
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import hashlib
import time
import redis.asyncio as redis
from collections import OrderedDict

# è¨­å®š uvloop ç‚ºé è¨­äº‹ä»¶å¾ªç’°
asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastAPI æ‡‰ç”¨
app = FastAPI(title="Heart Whisper MCP Server Ultra-Fast", version="5.0")

# è«‹æ±‚æ¨¡å‹
class DialogueRequest(BaseModel):
    npc_id: str
    message: str
    context: Optional[Dict[str, Any]] = {}
    session_id: Optional[str] = None

class FastNPCServer:
    """è¶…å¿«é€Ÿç‰ˆ NPC å°è©±æœå‹™å™¨"""

    def __init__(self):
        self.memories_dir = Path("memories")

        # NPC åç¨±æ˜ å°„
        self.npc_map = {
            "npc-1": "lupeixiu",
            "npc-2": "liuyucen",
            "npc-3": "chentingan"
        }

        # é è¼‰å…¥ç°¡åŒ–çš„å€‹æ€§è³‡æ–™ï¼ˆåªè¼‰å…¥æœ€æ ¸å¿ƒçš„éƒ¨åˆ†ï¼‰
        self.npc_personalities = self._load_minimal_personalities()

        # LRU è¨˜æ†¶å¿«å–
        self.response_cache = OrderedDict()
        self.max_cache_size = 200

        # Redis é€£æ¥
        self.redis_client = None
        self.redis_enabled = False

        logger.info(f"âœ… è¼‰å…¥ {len(self.npc_personalities)} å€‹ NPC ç°¡åŒ–å€‹æ€§")

    def _load_minimal_personalities(self) -> Dict[str, str]:
        """è¼‰å…¥æœ€å°åŒ–çš„NPCå€‹æ€§æè¿°"""
        personalities = {}

        # æ¥µç°¡å€‹æ€§æè¿°ï¼ˆè®“AIæ›´å¿«ç†è§£ï¼‰
        personalities["npc-1"] = "é™¸åŸ¹ä¿®ï¼šæº«æŸ”è—è¡“å®¶ï¼Œæ„›å¤¢æƒ³å’Œç¹ªç•«"
        personalities["npc-2"] = "åŠ‰å®‡å²‘ï¼šæ´»æ½‘é–‹æœ—ï¼Œæ„›ç”¨è¡¨æƒ…ç¬¦è™ŸğŸ˜Š"
        personalities["npc-3"] = "é™³åº­å®‰ï¼šç†æ€§é«”è²¼çš„æš–ç”·"

        return personalities

    async def init_redis(self):
        """åˆå§‹åŒ– Redis é€£æ¥"""
        try:
            self.redis_client = await redis.from_url(
                "redis://localhost:6379",
                encoding="utf-8",
                decode_responses=True
            )
            await self.redis_client.ping()
            self.redis_enabled = True
            logger.info("âœ… Redis é€£æ¥æˆåŠŸ")
        except Exception as e:
            logger.warning(f"Redis é€£æ¥å¤±æ•—: {e}")
            self.redis_enabled = False

    def _generate_cache_key(self, npc_id: str, message: str, context: Dict) -> str:
        """ç”Ÿæˆå¿«å–éµï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
        # æ­£è¦åŒ–è¨Šæ¯ä»¥æé«˜å¿«å–å‘½ä¸­ç‡
        normalized = self._normalize_message(message)
        key_data = f"{npc_id}:{normalized}:{context.get('mood', '')}"
        return f"fast_response:{hashlib.md5(key_data.encode()).hexdigest()}"

    def _normalize_message(self, message: str) -> str:
        """æ­£è¦åŒ–è¨Šæ¯ä»¥æé«˜å¿«å–å‘½ä¸­ç‡"""
        # ç§»é™¤å¤šé¤˜ç©ºæ ¼å’Œæ¨™é»ç¬¦è™Ÿ
        import re
        msg = message.lower().strip()
        msg = re.sub(r'[ï¼!ï¼Ÿ?ã€‚.ï¼Œ,ã€ï½~]', '', msg)
        msg = re.sub(r'\s+', ' ', msg)

        # å°‡ç›¸ä¼¼çš„å•å€™æ˜ å°„åˆ°åŒä¸€å€‹
        greetings = ['å—¨', 'hi', 'hello', 'ä½ å¥½', 'å“ˆå›‰', 'æ‚¨å¥½', 'hey']
        if any(g in msg for g in greetings):
            return 'ä½ å¥½'

        # å°‡ç›¸ä¼¼çš„å•é¡Œæ˜ å°„
        if 'æ€éº¼æ¨£' in msg or 'å¦‚ä½•' in msg or 'å¥½å—' in msg:
            if 'æœ€è¿‘' in msg or 'ä»Šå¤©' in msg:
                return 'æœ€è¿‘æ€éº¼æ¨£'

        if 'å–œæ­¡' in msg:
            if 'ä»€éº¼' in msg or 'å•¥' in msg:
                return 'ä½ å–œæ­¡ä»€éº¼'

        return msg

    async def _check_redis_cache(self, cache_key: str) -> Optional[str]:
        """æª¢æŸ¥ Redis å¿«å–"""
        if not self.redis_enabled:
            return None

        try:
            cached = await self.redis_client.get(cache_key)
            if cached:
                logger.info(f"ğŸ’¾ Redis å¿«å–å‘½ä¸­: {cache_key[:20]}...")
                return cached
        except Exception as e:
            logger.error(f"Redis è®€å–éŒ¯èª¤: {e}")

        return None

    async def _save_to_redis(self, cache_key: str, response: str):
        """ä¿å­˜åˆ° Redisï¼ˆå»¶é•· TTLï¼‰"""
        if not self.redis_enabled:
            return

        try:
            # å»¶é•· TTL åˆ° 2 å°æ™‚
            await self.redis_client.setex(cache_key, 7200, response)
            logger.info(f"ğŸ’¾ ä¿å­˜åˆ° Redis: {cache_key[:20]}... (TTL: 3600ç§’)")
        except Exception as e:
            logger.error(f"Redis ä¿å­˜éŒ¯èª¤: {e}")

    async def generate_fast_response(self, npc_id: str, message: str, context: Dict) -> str:
        """è¶…å¿«é€Ÿç”Ÿæˆå›æ‡‰"""

        # 1. æª¢æŸ¥å¿«å–
        cache_key = self._generate_cache_key(npc_id, message, context)

        # æª¢æŸ¥æœ¬åœ°å¿«å–
        if cache_key in self.response_cache:
            logger.info("âš¡ æœ¬åœ°å¿«å–å‘½ä¸­")
            return self.response_cache[cache_key]

        # æª¢æŸ¥ Redis
        cached = await self._check_redis_cache(cache_key)
        if cached:
            # æ›´æ–°æœ¬åœ°å¿«å–
            self._update_local_cache(cache_key, cached)
            return cached

        # 2. ä½¿ç”¨ç°¡åŒ–çš„ promptï¼Œä¸è¼‰å…¥æª”æ¡ˆ
        npc_personality = self.npc_personalities.get(npc_id, "å‹å–„çš„NPC")

        # å„ªåŒ–çš„promptï¼ˆæ›´çŸ­æ›´ç²¾æº–ï¼‰
        prompt = f"""{npc_personality}
ç”¨æˆ¶ï¼š{message}
å›æ‡‰ï¼ˆ1å¥è©±ï¼‰ï¼š"""

        # 3. ç›´æ¥èª¿ç”¨ Gemini CLIï¼ˆä¸ä½¿ç”¨ --include-directoriesï¼‰
        try:
            start_time = time.time()

            # ä½¿ç”¨ Gemini 2.5 Flash æ¨¡å‹ï¼ˆç§»é™¤ä¸æ”¯æ´çš„åƒæ•¸ï¼‰
            cmd = [
                "gemini",
                "-p", prompt,
                "--model", "gemini-2.5-flash"  # ä½¿ç”¨ 2.5 flash
            ]

            # è¨­ç½®ç’°å¢ƒè®Šæ•¸
            env = dict(os.environ)
            api_key = os.getenv('GEMINI_API_KEY')
            if api_key:
                env['GEMINI_API_KEY'] = str(api_key)

            # åŸ·è¡Œå‘½ä»¤ï¼ˆæ¸›å°‘ timeoutï¼‰
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                env=env
            )

            try:
                stdout, stderr = await asyncio.wait_for(
                    process.communicate(),
                    timeout=15  # 15ç§’è¶…æ™‚ï¼ˆGemini 2.5 Flashéœ€è¦æ›´å¤šæ™‚é–“ï¼‰
                )
            except asyncio.TimeoutError:
                process.kill()
                logger.error("Gemini è¶…æ™‚ï¼ˆ15ç§’ï¼‰")
                return self._get_fallback_response(npc_id, message)

            elapsed = time.time() - start_time
            logger.info(f"âš¡ Gemini å›æ‡‰æ™‚é–“: {elapsed:.2f}ç§’")

            if process.returncode == 0 and stdout:
                response = stdout.decode('utf-8').strip()

                # æ¸…ç†å›æ‡‰
                response = response.replace('```', '').strip()
                if not response:
                    response = self._get_fallback_response(npc_id, message)

                # å„²å­˜åˆ°å¿«å–
                self._update_local_cache(cache_key, response)
                await self._save_to_redis(cache_key, response)

                return response
            else:
                logger.error(f"Gemini éŒ¯èª¤: {stderr.decode('utf-8') if stderr else 'Unknown'}")
                return self._get_fallback_response(npc_id, message)

        except Exception as e:
            logger.error(f"ç”Ÿæˆå›æ‡‰éŒ¯èª¤: {e}")
            return self._get_fallback_response(npc_id, message)

    def _update_local_cache(self, key: str, value: str):
        """æ›´æ–°æœ¬åœ° LRU å¿«å–"""
        # å¦‚æœå·²å­˜åœ¨ï¼Œå…ˆåˆªé™¤ï¼ˆç‚ºäº†æ›´æ–°é †åºï¼‰
        if key in self.response_cache:
            del self.response_cache[key]

        # æ·»åŠ åˆ°æœ€å¾Œ
        self.response_cache[key] = value

        # é™åˆ¶å¤§å°
        if len(self.response_cache) > self.max_cache_size:
            # åˆªé™¤æœ€èˆŠçš„ï¼ˆç¬¬ä¸€å€‹ï¼‰
            self.response_cache.popitem(last=False)

    def _get_fallback_response(self, npc_id: str, message: str) -> str:
        """å‚™ç”¨å›æ‡‰ï¼ˆç•¶ Gemini å¤±æ•—æ™‚ï¼‰"""
        fallback_responses = {
            "npc-1": [
                "è®“æˆ‘æƒ³æƒ³...é€™å€‹å•é¡Œå¾ˆæœ‰æ„æ€å‘¢ã€‚",
                "å—¯...æˆ–è¨±æˆ‘å€‘å¯ä»¥å¾å¦ä¸€å€‹è§’åº¦çœ‹å¾…é€™ä»¶äº‹ã€‚",
                "é€™è®“æˆ‘æƒ³åˆ°äº†ä¸€å¹…ç•«..."
            ],
            "npc-2": [
                "å“‡ï¼é€™å€‹å•é¡Œå¥½æœ‰è¶£ï¼",
                "è®“æˆ‘æƒ³æƒ³çœ‹...å•Šï¼æˆ‘çŸ¥é“äº†ï¼",
                "å˜¿å˜¿ï¼Œä½ èªªå¾—å°è€¶ï¼"
            ],
            "npc-3": [
                "é€™æ˜¯å€‹å€¼å¾—æ·±æ€çš„å•é¡Œã€‚",
                "æœ‰è¶£çš„è§€é»ï¼Œæˆ‘èªç‚º...",
                "å¾é‚è¼¯ä¸Šä¾†èªªï¼Œé€™å¾ˆåˆç†ã€‚"
            ]
        }

        import random
        responses = fallback_responses.get(npc_id, ["å—¯ï¼Œè®“æˆ‘æƒ³æƒ³..."])
        return random.choice(responses)

    async def get_status(self) -> Dict:
        """ç²å–æœå‹™ç‹€æ…‹"""
        return {
            "status": "running",
            "npcs_loaded": len(self.npc_personalities),
            "local_cache_size": len(self.response_cache),
            "redis_enabled": self.redis_enabled,
            "response_time_target": "2-5 seconds",
            "optimization": "Ultra-fast mode with minimal context"
        }

# å‰µå»ºæœå‹™å¯¦ä¾‹
npc_server = FastNPCServer()

@app.on_event("startup")
async def startup_event():
    """å•Ÿå‹•äº‹ä»¶"""
    logger.info("ğŸš€ å•Ÿå‹•è¶…å¿«é€Ÿ MCP æœå‹™å™¨...")
    await npc_server.init_redis()

    # é ç†±æ›´å¤šå¸¸è¦‹å°è©±
    logger.info("ğŸ”¥ é ç†±å¸¸è¦‹å°è©±...")
    common_messages = [
        "ä½ å¥½", "å—¨", "ä½ å¥½å—", "æœ€è¿‘æ€éº¼æ¨£",
        "ä»Šå¤©å¤©æ°£çœŸå¥½", "ä½ åœ¨åšä»€éº¼", "ä½ å–œæ­¡ä»€éº¼",
        "å†è¦‹", "è¬è¬", "å°ä¸èµ·", "æ²’é—œä¿‚",
        "ä½ è¦ºå¾—å‘¢", "çœŸçš„å—", "å¥½å•Š", "æˆ‘å¾ˆé–‹å¿ƒ"
    ]
    for npc_id in npc_server.npc_map.keys():
        for msg in common_messages:
            asyncio.create_task(
                npc_server.generate_fast_response(npc_id, msg, {})
            )

    logger.info("âœ… MCP è¶…å¿«é€Ÿæœå‹™å™¨å•Ÿå‹•å®Œæˆ")

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.get("/status")
async def get_status():
    """ç²å–æœå‹™ç‹€æ…‹"""
    return await npc_server.get_status()

@app.post("/generate")
async def generate_dialogue(request: DialogueRequest):
    """ç”ŸæˆNPCå°è©±ï¼ˆè¶…å¿«é€Ÿç‰ˆï¼‰"""
    start_time = time.time()

    try:
        # é©—è­‰ NPC ID
        if request.npc_id not in npc_server.npc_map:
            raise HTTPException(status_code=404, detail=f"NPC {request.npc_id} not found")

        # ç”Ÿæˆå›æ‡‰
        response = await npc_server.generate_fast_response(
            request.npc_id,
            request.message,
            request.context
        )

        elapsed = time.time() - start_time

        return {
            "response": response,
            "timing": {
                "total": elapsed,
                "optimized": True,
                "mode": "ultra-fast"
            }
        }

    except Exception as e:
        logger.error(f"ç”Ÿæˆå°è©±éŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/cache/clear")
async def clear_cache():
    """æ¸…ç©ºå¿«å–"""
    npc_server.response_cache.clear()
    if npc_server.redis_enabled:
        try:
            keys = await npc_server.redis_client.keys("fast_response:*")
            if keys:
                await npc_server.redis_client.delete(*keys)
        except Exception as e:
            logger.error(f"æ¸…ç©º Redis å¿«å–å¤±æ•—: {e}")

    return {"message": "Cache cleared", "timestamp": datetime.now().isoformat()}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8765, log_level="info")