#!/usr/bin/env python3
"""
å¿ƒèªå°é® NPC å°è©±ç”Ÿæˆæœå‹™ - é«˜æ•ˆèƒ½å¸¸é§æœå‹™ç‰ˆæœ¬
ä½¿ç”¨ FastAPI + uvicorn å»ºç«‹ HTTP æœå‹™ï¼Œé¿å…é‡è¤‡å•Ÿå‹• Python å’Œæª”æ¡ˆ I/O
ä¿ç•™ Gemini CLI çš„æ€è€ƒæ¨¡å¼å’Œè¶…å¤§çª—å£å„ªå‹¢
"""

import os
import json
import subprocess
import asyncio
import time
import logging
from typing import Optional, Dict, Any, List
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from functools import lru_cache
import hashlib

# FastAPI ç›¸é—œ
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# é…ç½®å¸¸æ•¸
GEMINI_CLI_COMMAND = "gemini"
PERSONALITIES_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'personalities')
CACHE_SIZE = 100  # LRU å¿«å–å¤§å°
GEMINI_TIMEOUT = 30  # Gemini CLI è¶…æ™‚ç§’æ•¸

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
from dotenv import load_dotenv
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
env_path = os.path.join(project_root, '.env')
load_dotenv(env_path)

GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
if not GEMINI_API_KEY:
    # å˜—è©¦å¾ backend/.env è®€å–
    backend_env = os.path.join(os.path.dirname(os.path.abspath(__file__)), '.env')
    if os.path.exists(backend_env):
        load_dotenv(backend_env)
        GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

# FastAPI æ‡‰ç”¨
app = FastAPI(title="å¿ƒèªå°é® Gemini æœå‹™")

# CORS ä¸­é–“ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è«‹æ±‚æ¨¡å‹
class NPCRequest(BaseModel):
    message: str
    npcData: Dict[str, Any]
    context: Optional[Dict[str, Any]] = {}

class NPCResponse(BaseModel):
    content: str
    processingTime: float
    cached: bool = False

# å…¨åŸŸè®Šæ•¸
personality_cache: Dict[str, Dict[str, str]] = {}
response_cache: Dict[str, str] = {}
executor = ThreadPoolExecutor(max_workers=3)  # åŸ·è¡Œç·’æ± 


class GeminiService:
    """å„ªåŒ–çš„ Gemini æœå‹™é¡"""
    
    def __init__(self):
        self.personalities = self._preload_all_personalities()
        self.gemini_process = None  # å¯é¸ï¼šä¿æŒ Gemini CLI é€²ç¨‹
        logger.info(f"âœ… é è¼‰å…¥ {len(self.personalities)} å€‹ NPC å€‹æ€§æª”æ¡ˆ")
    
    def _preload_all_personalities(self) -> Dict[str, Dict[str, str]]:
        """é è¼‰å…¥æ‰€æœ‰å€‹æ€§æª”æ¡ˆåˆ°è¨˜æ†¶é«”"""
        personalities = {}
        name_mapping = {
            'æµç¾½å²‘': 'liuyucen',
            'é‹é…å’»': 'lupeixiu',
            'æ²‰åœé': 'chentingan'
        }
        
        for npc_name, filename in name_mapping.items():
            personality_file = os.path.join(PERSONALITIES_DIR, f"{filename}_personality.txt")
            chat_history_file = os.path.join(PERSONALITIES_DIR, f"{filename}_chat_history.txt")
            
            data = {'personality': '', 'chat_history': ''}
            
            try:
                if os.path.exists(personality_file):
                    with open(personality_file, 'r', encoding='utf-8') as f:
                        data['personality'] = self._clean_text(f.read())
                
                if os.path.exists(chat_history_file):
                    with open(chat_history_file, 'r', encoding='utf-8') as f:
                        data['chat_history'] = self._clean_text(f.read())
                
                personalities[npc_name] = data
                logger.info(f"è¼‰å…¥ {npc_name} çš„å€‹æ€§è³‡æ–™")
            except Exception as e:
                logger.error(f"è¼‰å…¥ {npc_name} å¤±æ•—: {e}")
        
        return personalities
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ä¸­çš„ç‰¹æ®Šå­—ç¬¦"""
        unwanted_chars = ['\u2068', '\u2069', '\u202a', '\u202b', '\u202c', '\u202d', '\u202e']
        for char in unwanted_chars:
            text = text.replace(char, '')
        return text.strip()
    
    def _get_cache_key(self, message: str, npc_data: Dict) -> str:
        """ç”Ÿæˆå¿«å–éµ"""
        key_data = f"{message}:{npc_data.get('id')}:{npc_data.get('relationshipLevel', 1)}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    async def generate_response(self, message: str, npc_data: Dict, context: Dict) -> str:
        """ç”Ÿæˆ NPC å›æ‡‰ï¼ˆç•°æ­¥ç‰ˆæœ¬ï¼‰"""
        start_time = time.time()
        
        # æª¢æŸ¥è¨˜æ†¶é«”å¿«å–
        cache_key = self._get_cache_key(message, npc_data)
        if cache_key in response_cache:
            logger.info(f"âœ… å¿«å–å‘½ä¸­ï¼š{cache_key[:8]}")
            return response_cache[cache_key]
        
        # æ§‹å»º prompt
        prompt = self._build_optimized_prompt(message, npc_data, context)
        
        # ç•°æ­¥åŸ·è¡Œ Gemini CLI
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            executor,
            self._call_gemini_cli_optimized,
            prompt
        )
        
        # å„²å­˜åˆ°å¿«å–ï¼ˆLRU é‚è¼¯ï¼‰
        if len(response_cache) >= CACHE_SIZE:
            # ç§»é™¤æœ€èˆŠçš„é …ç›®
            oldest_key = next(iter(response_cache))
            del response_cache[oldest_key]
        response_cache[cache_key] = response
        
        elapsed = time.time() - start_time
        logger.info(f"âš¡ ç”Ÿæˆå›æ‡‰è€—æ™‚ï¼š{elapsed:.2f}ç§’")
        
        return response
    
    def _build_optimized_prompt(self, message: str, npc_data: Dict, context: Dict) -> str:
        """æ§‹å»ºå„ªåŒ–çš„ prompt"""
        npc_name = npc_data.get('name', 'æœªçŸ¥')
        
        # å¾é è¼‰å…¥çš„å¿«å–ç²å–å€‹æ€§è³‡æ–™
        personality_data = self.personalities.get(npc_name, {})
        
        # å¾ context æå–å…ƒå®‡å®™è³‡æ–™
        shared_memories = context.get('sharedMemories', [])
        other_npc_memories = context.get('otherNPCMemories', [])
        session_messages = context.get('sessionMessages', [])
        
        # æ ¼å¼åŒ–è¨˜æ†¶ï¼ˆåªå–å‰å¹¾æ¢ï¼Œæ¸›å°‘ token ä½¿ç”¨ï¼‰
        my_memories = '\n'.join([f"- {mem}" for mem in shared_memories[:3]])
        others_memories = '\n'.join([f"- {mem}" for mem in other_npc_memories[:2]])
        session_history = '\n'.join(session_messages[-5:])  # æœ€è¿‘ 5 æ¢
        
        prompt = f"""ä½ æ˜¯å¿ƒèªå°é®å…ƒå®‡å®™ä¸­çš„ NPCã€Œ{npc_name}ã€ã€‚

ã€è§’è‰²è¨­å®šã€‘
{personality_data.get('personality', '')[:500]}

ã€å°è©±é¢¨æ ¼ã€‘
{personality_data.get('chat_history', '')[:300]}

ã€æˆ‘çš„è¨˜æ†¶ã€‘
{my_memories or 'ï¼ˆæš«ç„¡ï¼‰'}

ã€è½èªªçš„äº‹ã€‘
{others_memories or 'ï¼ˆæš«ç„¡ï¼‰'}

ã€ç•¶å‰å°è©±ã€‘
{session_history}

ã€ç‹€æ…‹ã€‘
å¿ƒæƒ…ï¼š{npc_data.get('currentMood', 'neutral')}
é—œä¿‚ï¼š{npc_data.get('relationshipLevel', 1)}/10

ç©å®¶ï¼š{message}
{npc_name}ï¼š"""
        
        return prompt
    
    def _call_gemini_cli_optimized(self, prompt: str) -> str:
        """å„ªåŒ–çš„ Gemini CLI èª¿ç”¨"""
        try:
            # ä½¿ç”¨ subprocess ä½†ä¸å‰µå»ºè‡¨æ™‚æª”æ¡ˆ
            cmd = [GEMINI_CLI_COMMAND, "--no-telemetry", "--no-telemetry-log-prompts", "-p"]
            
            # è¨­å®šç’°å¢ƒè®Šæ•¸
            env = os.environ.copy()
            env['GEMINI_API_KEY'] = GEMINI_API_KEY
            
            # ç›´æ¥é€šé stdin å‚³é prompt
            result = subprocess.run(
                cmd,
                input=prompt,
                capture_output=True,
                text=True,
                encoding='utf-8',
                timeout=GEMINI_TIMEOUT,
                env=env
            )
            
            if result.returncode != 0:
                logger.error(f"Gemini CLI éŒ¯èª¤ï¼š{result.stderr}")
                raise Exception("Gemini CLI åŸ·è¡Œå¤±æ•—")
            
            return result.stdout.strip()
            
        except subprocess.TimeoutExpired:
            logger.error("Gemini CLI è¶…æ™‚")
            return "æŠ±æ­‰ï¼Œæˆ‘éœ€è¦æƒ³ä¸€æƒ³..."
        except Exception as e:
            logger.error(f"Gemini CLI éŒ¯èª¤ï¼š{e}")
            return "å—¯ï¼Œè®“æˆ‘æ•´ç†ä¸€ä¸‹æ€ç·’..."


# åˆå§‹åŒ–æœå‹™
gemini_service = GeminiService()


@app.get("/")
async def root():
    """å¥åº·æª¢æŸ¥"""
    return {
        "status": "healthy",
        "service": "å¿ƒèªå°é® Gemini æœå‹™",
        "cache_size": len(response_cache),
        "personalities_loaded": len(gemini_service.personalities)
    }


@app.post("/generate", response_model=NPCResponse)
async def generate_npc_response(request: NPCRequest):
    """ç”Ÿæˆ NPC å›æ‡‰çš„ API ç«¯é»"""
    start_time = time.time()
    
    try:
        # åˆä½µ context è³‡æ–™åˆ° npcData
        npc_data = request.npcData.copy()
        if request.context:
            npc_data.update(request.context)
        
        # ç”Ÿæˆå›æ‡‰
        response = await gemini_service.generate_response(
            request.message,
            npc_data,
            request.context or {}
        )
        
        processing_time = time.time() - start_time
        
        # æª¢æŸ¥æ˜¯å¦ä¾†è‡ªå¿«å–
        cache_key = gemini_service._get_cache_key(request.message, npc_data)
        cached = cache_key in response_cache
        
        return NPCResponse(
            content=response,
            processingTime=processing_time,
            cached=cached
        )
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆå›æ‡‰å¤±æ•—ï¼š{e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/clear-cache")
async def clear_cache():
    """æ¸…ç©ºå¿«å–"""
    response_cache.clear()
    return {"message": "å¿«å–å·²æ¸…ç©º", "timestamp": datetime.now().isoformat()}


@app.get("/stats")
async def get_stats():
    """ç²å–çµ±è¨ˆè³‡æ–™"""
    return {
        "cache_entries": len(response_cache),
        "cache_size_mb": sum(len(v.encode()) for v in response_cache.values()) / (1024 * 1024),
        "personalities_loaded": list(gemini_service.personalities.keys()),
        "thread_pool_size": executor._max_workers
    }


@app.on_event("startup")
async def startup_event():
    """å•Ÿå‹•æ™‚åŸ·è¡Œ"""
    logger.info("ğŸš€ å¿ƒèªå°é® Gemini æœå‹™å•Ÿå‹•ä¸­...")
    logger.info(f"âœ… è¼‰å…¥ {len(gemini_service.personalities)} å€‹ NPC å€‹æ€§")
    logger.info(f"âœ… Gemini API Key: {'å·²è¨­ç½®' if GEMINI_API_KEY else 'æœªè¨­ç½®'}")
    
    # é ç†±å¿«å–ï¼ˆå¯é¸ï¼‰
    warmup_messages = ["ä½ å¥½", "ä»Šå¤©å¤©æ°£çœŸå¥½", "æœ€è¿‘æ€éº¼æ¨£"]
    npc_ids = ['npc-1', 'npc-2', 'npc-3']
    
    for npc_id in npc_ids:
        for msg in warmup_messages[:1]:  # åªé ç†±ä¸€å€‹è¨Šæ¯
            try:
                await gemini_service.generate_response(
                    msg,
                    {'id': npc_id, 'name': list(gemini_service.personalities.keys())[0]},
                    {}
                )
            except:
                pass
    
    logger.info("âœ… æœå‹™å°±ç·’")


@app.on_event("shutdown")
async def shutdown_event():
    """é—œé–‰æ™‚åŸ·è¡Œ"""
    logger.info("æ­£åœ¨é—œé–‰æœå‹™...")
    executor.shutdown(wait=True)


if __name__ == "__main__":
    # ä½¿ç”¨ uvicorn å•Ÿå‹•é«˜æ•ˆèƒ½æœå‹™å™¨
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8765,
        log_level="info",
        access_log=True,
        # ä½¿ç”¨å¤šå€‹ worker é€²ç¨‹ï¼ˆç”Ÿç”¢ç’°å¢ƒï¼‰
        # workers=2
    )