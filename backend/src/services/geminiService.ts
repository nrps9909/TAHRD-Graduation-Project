import { GoogleGenerativeAI } from '@google/generative-ai'
import { logger } from '../utils/logger'
import { spawn } from 'child_process'
import * as path from 'path'

interface NPCPersonality {
  id: string
  name: string
  personality: string
  backgroundStory?: string
  currentMood: string
}

interface ConversationContext {
  recentMessages: Array<{
    speaker: 'user' | 'npc'
    content: string
    timestamp: Date
  }>
  relationshipLevel: number
  trustLevel: number
  affectionLevel: number
  userDiaryEntries?: string[]
}

interface AIResponse {
  content: string
  emotionTag: string
  suggestedActions: string[]
  memoryFlowerData?: {
    flowerType: string
    emotionColor: string
  }
  relationshipImpact: {
    trustChange: number
    affectionChange: number
    levelChange: number
  }
  moodChange?: string
}

class GeminiService {
  private genAI?: GoogleGenerativeAI
  private model?: any
  private useGeminiCLI: boolean

  constructor() {
    // å¯ä»¥é€éç’°å¢ƒè®Šæ•¸æ§åˆ¶æ˜¯å¦ä½¿ç”¨ Gemini CLI
    this.useGeminiCLI = process.env.USE_GEMINI_CLI === 'true'
    
    const apiKey = process.env.GEMINI_API_KEY
    if (!this.useGeminiCLI && (!apiKey || apiKey === 'your-api-key')) {
      throw new Error('GEMINI_API_KEY is required when USE_GEMINI_CLI is false')
    }
    
    if (!this.useGeminiCLI) {
      this.genAI = new GoogleGenerativeAI(apiKey!)
      this.model = this.genAI.getGenerativeModel({ model: 'gemini-1.5-pro' })
    }
  }

  async generateNPCResponse(
    npcPersonality: NPCPersonality,
    userMessage: string,
    context: ConversationContext
  ): Promise<AIResponse> {
    try {
      // æ ¹æ“šé…ç½®é¸æ“‡ä½¿ç”¨ CLI æˆ–ç›´æ¥ API
      if (this.useGeminiCLI) {
        return await this.generateNPCResponseWithCLI(npcPersonality, userMessage, context)
      } else {
        return await this.generateNPCResponseWithAPI(npcPersonality, userMessage, context)
      }
    } catch (error) {
      logger.error('Gemini generation error:', error)
      
      // é™ç´šè™•ç† - è¿”å›é è¨­å›æ‡‰
      return this.getFallbackResponse(npcPersonality, userMessage)
    }
  }

  private async generateNPCResponseWithAPI(
    npcPersonality: NPCPersonality,
    userMessage: string,
    context: ConversationContext
  ): Promise<AIResponse> {
    const prompt = this.buildPrompt(npcPersonality, userMessage, context)
    
    const result = await this.model.generateContent(prompt)
    const response = await result.response
    const text = response.text()
    
    // è§£æçµæ§‹åŒ–å›æ‡‰
    return this.parseAIResponse(text, npcPersonality)
  }

  private async generateNPCResponseWithCLI(
    npcPersonality: NPCPersonality,
    userMessage: string,
    context: ConversationContext
  ): Promise<AIResponse> {
    // å»ºæ§‹ç”¨æ–¼ CLI çš„å°è©±ä¸Šä¸‹æ–‡
    const conversationPrompt = this.buildConversationPrompt(npcPersonality, userMessage, context)
    
    // å‘¼å« gemini.py CLI
    const cliResponse = await this.callGeminiCLI(conversationPrompt, npcPersonality)
    
    // è§£æ CLI å›æ‡‰
    return this.parseAIResponse(cliResponse, npcPersonality)
  }

  private async callGeminiCLI(prompt: string, npcPersonality: NPCPersonality | null = null): Promise<string> {
    return new Promise((resolve, reject) => {
      const projectRoot = path.resolve(__dirname, '../../../')
      const geminiScriptPath = path.join(projectRoot, 'backend', 'npc_dialogue_service.py')
      
      // æº–å‚™åƒæ•¸
      const args = [geminiScriptPath, '--chat', prompt]
      
      // å¦‚æœæœ‰ NPC å€‹æ€§æ•¸æ“šå‰‡æ·»åŠ 
      if (npcPersonality) {
        const npcData = JSON.stringify({
          name: npcPersonality.name,
          personality: npcPersonality.personality,
          backgroundStory: npcPersonality.backgroundStory,
          currentMood: npcPersonality.currentMood
        })
        args.push('--npc-data', npcData)
      }
      
      // åŸ·è¡Œ Python è…³æœ¬
      const pythonProcess = spawn('python3', args, {
        cwd: projectRoot,
        env: { ...process.env }
      })
      
      let output = ''
      let errorOutput = ''
      
      pythonProcess.stdout.on('data', (data) => {
        output += data.toString()
      })
      
      pythonProcess.stderr.on('data', (data) => {
        errorOutput += data.toString()
      })
      
      pythonProcess.on('close', (code) => {
        if (code === 0) {
          // æå–å¯¦éš›çš„ AI å›æ‡‰ï¼ˆç§»é™¤æ—¥èªŒä¿¡æ¯ï¼‰
          const cleanOutput = this.extractAIResponseFromCLIOutput(output)
          resolve(cleanOutput)
        } else {
          logger.error(`Gemini CLI failed with code ${code}: ${errorOutput}`)
          reject(new Error(`Gemini CLI failed: ${errorOutput}`))
        }
      })
      
      pythonProcess.on('error', (error) => {
        logger.error('Failed to start Gemini CLI process:', error)
        reject(error)
      })
    })
  }

  private extractAIResponseFromCLIOutput(output: string): string {
    // æŸ¥æ‰¾ "NPC å›æ‡‰ï¼š" ä¹‹å¾Œçš„å…§å®¹
    const responseMarker = 'ğŸ¤– NPC å›æ‡‰ï¼š'
    const startIndex = output.indexOf(responseMarker)
    
    if (startIndex === -1) {
      // å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¨™è¨˜ï¼Œå˜—è©¦æå–æ‰€æœ‰éæ—¥èªŒå…§å®¹
      const lines = output.split('\n')
      const contentLines = lines.filter(line => 
        !line.includes('INFO') && 
        !line.includes('âœ…') && 
        !line.includes('===') &&
        line.trim().length > 0
      )
      return contentLines.join('\n').trim()
    }
    
    // æå–æ¨™è¨˜å¾Œçš„å…§å®¹
    const afterMarker = output.substring(startIndex + responseMarker.length)
    const lines = afterMarker.split('\n')
    
    // ç§»é™¤åˆ†éš”ç·šå’Œç©ºè¡Œ
    const contentLines = lines.filter(line => 
      !line.includes('===') && 
      line.trim().length > 0
    )
    
    return contentLines.join('\n').trim()
  }

  private buildConversationPrompt(
    npc: NPCPersonality,
    userMessage: string,
    context: ConversationContext
  ): string {
    const recentHistory = context.recentMessages
      .slice(-5)
      .map(msg => `${msg.speaker === 'user' ? 'ç©å®¶' : npc.name}: ${msg.content}`)
      .join('\n')

    return `
å°è©±æ­·å²ï¼š
${recentHistory}

é—œä¿‚ç‹€æ…‹ï¼š
- é—œä¿‚ç­‰ç´š: ${context.relationshipLevel}/10
- ä¿¡ä»»åº¦: ${Math.round(context.trustLevel * 100)}%
- å¥½æ„Ÿåº¦: ${Math.round(context.affectionLevel * 100)}%

ç•¶å‰ç©å®¶è¨Šæ¯ï¼š
${userMessage}

è«‹ä»¥ ${npc.name} çš„èº«ä»½å›æ‡‰ï¼Œä¸¦è¿”å›æœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚
    `.trim()
  }

  private buildPrompt(
    npc: NPCPersonality,
    userMessage: string,
    context: ConversationContext
  ): string {
    const recentHistory = context.recentMessages
      .slice(-5) // åªå–æœ€è¿‘5æ¢æ¶ˆæ¯
      .map(msg => `${msg.speaker === 'user' ? 'ç©å®¶' : npc.name}: ${msg.content}`)
      .join('\n')

    return `
ä½ æ˜¯ã€Œå¿ƒèªå°é®ã€ä¸­çš„NPCè§’è‰²ã€Œ${npc.name}ã€ã€‚é€™æ˜¯ä¸€å€‹ç™‚ç™’å‘çš„ç¤¾äº¤éŠæˆ²ï¼Œé‡é»åœ¨æ–¼å»ºç«‹æ·±åº¦çš„æƒ…æ„Ÿé€£çµã€‚

ã€è§’è‰²è¨­å®šã€‘
å§“å: ${npc.name}
å€‹æ€§: ${npc.personality}
èƒŒæ™¯æ•…äº‹: ${npc.backgroundStory || 'å¾…ç™¼æ˜'}
ç•¶å‰æƒ…ç·’: ${npc.currentMood}

ã€é—œä¿‚ç‹€æ…‹ã€‘
é—œä¿‚ç­‰ç´š: ${context.relationshipLevel}/10
ä¿¡ä»»åº¦: ${Math.round(context.trustLevel * 100)}%
å¥½æ„Ÿåº¦: ${Math.round(context.affectionLevel * 100)}%

ã€å°è©±æ­·å²ã€‘
${recentHistory}

ã€ç•¶å‰ç©å®¶è¨Šæ¯ã€‘
ç©å®¶: ${userMessage}

ã€å›æ‡‰æŒ‡å—ã€‘
1. ä¿æŒè§’è‰²ä¸€è‡´æ€§ï¼Œé«”ç¾å€‹æ€§ç‰¹å¾µ
2. æ ¹æ“šé—œä¿‚ç­‰ç´šèª¿æ•´è¦ªå¯†ç¨‹åº¦å’Œè©±é¡Œæ·±åº¦
3. è€ƒæ…®ç•¶å‰æƒ…ç·’å½±éŸ¿å°è©±é¢¨æ ¼
4. å±•ç¾çœŸå¯¦çš„æƒ…æ„Ÿåæ‡‰ï¼Œä¸å®Œç¾ä½†çœŸå¯¦
5. é©æ™‚åˆ†äº«å€‹äººæƒ³æ³•æˆ–å›æ†¶
6. å°ç©å®¶è¡¨ç¾å‡ºçœŸæ­£çš„é—œå¿ƒå’Œèˆˆè¶£

è«‹ç”¨ä»¥ä¸‹JSONæ ¼å¼å›æ‡‰ï¼š
{
  "content": "å°è©±å…§å®¹ï¼ˆè‡ªç„¶ã€æº«æš–ã€ç¬¦åˆè§’è‰²æ€§æ ¼ï¼‰",
  "emotionTag": "æƒ…ç·’æ¨™ç±¤ï¼ˆå¦‚ï¼šæº«æš–ã€é—œæ‡·ã€æ€è€ƒã€é–‹å¿ƒã€æ“”å¿ƒç­‰ï¼‰",
  "suggestedActions": ["å»ºè­°çš„å¾ŒçºŒè©±é¡Œæˆ–è¡Œå‹•"],
  "memoryFlowerData": {
    "flowerType": "è¨˜æ†¶èŠ±æœµé¡å‹ï¼ˆå¦‚æœé€™æ˜¯é‡è¦å°è©±æ™‚åˆ»ï¼‰",
    "emotionColor": "èŠ±æœµé¡è‰²ï¼ˆå¦‚ï¼šwarm_pink, gentle_blue, soft_yellowç­‰ï¼‰"
  },
  "relationshipImpact": {
    "trustChange": 0.1,
    "affectionChange": 0.05,
    "levelChange": 0
  },
  "moodChange": "æ–°çš„æƒ…ç·’ç‹€æ…‹ï¼ˆå¦‚æœæœ‰è®ŠåŒ–ï¼‰"
}

è«‹ç¢ºä¿å›æ‡‰æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚
    `.trim()
  }

  private parseAIResponse(text: string, npc: NPCPersonality): AIResponse {
    try {
      // å˜—è©¦è§£æJSONå›æ‡‰
      const cleanText = text.replace(/```json\n?|\n?```/g, '').trim()
      const parsed = JSON.parse(cleanText)
      
      // é©—è­‰å¿…è¦æ¬„ä½
      if (!parsed.content) {
        throw new Error('Missing content field')
      }
      
      return {
        content: parsed.content,
        emotionTag: parsed.emotionTag || 'neutral',
        suggestedActions: parsed.suggestedActions || [],
        memoryFlowerData: parsed.memoryFlowerData,
        relationshipImpact: {
          trustChange: parsed.relationshipImpact?.trustChange || 0,
          affectionChange: parsed.relationshipImpact?.affectionChange || 0,
          levelChange: parsed.relationshipImpact?.levelChange || 0,
        },
        moodChange: parsed.moodChange,
      }
      
    } catch (error) {
      logger.warn('Failed to parse AI response as JSON, using fallback:', error)
      
      // å¦‚æœè§£æå¤±æ•—ï¼Œå˜—è©¦æå–åŸºæœ¬å›æ‡‰
      return {
        content: text || 'æŠ±æ­‰ï¼Œæˆ‘ä¸€æ™‚ä¸çŸ¥é“è©²èªªä»€éº¼...',
        emotionTag: 'confused',
        suggestedActions: [],
        relationshipImpact: {
          trustChange: 0,
          affectionChange: 0,
          levelChange: 0,
        },
      }
    }
  }

  private getFallbackResponse(npc: NPCPersonality, userMessage: string): AIResponse {
    const fallbackResponses = [
      'çœŸçš„å—ï¼Ÿå‘Šè¨´æˆ‘æ›´å¤šå§ã€‚',
      'é€™è½èµ·ä¾†å¾ˆæœ‰è¶£å‘¢ã€‚',
      'æˆ‘åœ¨æƒ³ä½ å‰›æ‰èªªçš„è©±...',
      'å—¯ï¼Œæˆ‘è¦ºå¾—æˆ‘éœ€è¦æ™‚é–“æ¶ˆåŒ–ä¸€ä¸‹ã€‚',
      'ä½ ç¸½æ˜¯æœ‰é€™éº¼å¤šæƒ³æ³•ï¼Œæˆ‘å¾ˆå–œæ­¡å’Œä½ èŠå¤©ã€‚',
    ]
    
    const randomResponse = fallbackResponses[Math.floor(Math.random() * fallbackResponses.length)]
    
    return {
      content: randomResponse,
      emotionTag: 'thoughtful',
      suggestedActions: ['ç¹¼çºŒå°è©±'],
      relationshipImpact: {
        trustChange: 0.01,
        affectionChange: 0.01,
        levelChange: 0,
      },
    }
  }

  async generateMemoryFlowerDescription(
    conversationContent: string,
    emotionTag: string
  ): Promise<{
    flowerType: string
    emotionColor: string
    description: string
  }> {
    try {
      const prompt = `
åŸºæ–¼ä»¥ä¸‹å°è©±å…§å®¹å’Œæƒ…ç·’ï¼Œç‚ºã€Œå¿ƒèªå°é®ã€çš„è¨˜æ†¶èŠ±åœ’ç³»çµ±ç”Ÿæˆä¸€æœµè¨˜æ†¶èŠ±ï¼š

å°è©±å…§å®¹: ${conversationContent}
æƒ…ç·’æ¨™ç±¤: ${emotionTag}

è«‹ä»¥JSONæ ¼å¼å›æ‡‰ï¼š
{
  "flowerType": "èŠ±æœµé¡å‹ï¼ˆå¦‚ï¼šcherry_blossom, sunflower, lavender, roseç­‰ï¼‰",
  "emotionColor": "æƒ…ç·’è‰²å½©ï¼ˆå¦‚ï¼šwarm_pink, gentle_blue, soft_yellowç­‰ï¼‰",
  "description": "é€™æœµèŠ±ä»£è¡¨çš„è¨˜æ†¶æè¿°"
}
      `.trim()

      const result = await this.model.generateContent(prompt)
      const response = await result.response
      const text = response.text()
      
      const cleanText = text.replace(/```json\n?|\n?```/g, '').trim()
      const parsed = JSON.parse(cleanText)
      
      return {
        flowerType: parsed.flowerType || 'wildflower',
        emotionColor: parsed.emotionColor || 'soft_white',
        description: parsed.description || 'ä¸€æ®µç¾å¥½çš„å›æ†¶',
      }
      
    } catch (error) {
      logger.error('Failed to generate memory flower:', error)
      
      // é™ç´šè™•ç†
      return {
        flowerType: 'wildflower',
        emotionColor: 'soft_white',
        description: 'ä¸€æ®µçè²´çš„å°è©±è¨˜æ†¶',
      }
    }
  }

  async generateNPCLetter(
    npc: NPCPersonality,
    relationshipLevel: number,
    recentEvents: string[]
  ): Promise<{
    subject: string
    content: string
  }> {
    try {
      const prompt = `
ä½ æ˜¯ã€Œ${npc.name}ã€ï¼Œæƒ³è¦ä¸»å‹•å¯«ä¿¡çµ¦ç©å®¶ã€‚

è§’è‰²è¨­å®š:
${npc.personality}

é—œä¿‚ç­‰ç´š: ${relationshipLevel}/10
æœ€è¿‘çš„äº‹ä»¶: ${recentEvents.join(', ')}

è«‹å¯«ä¸€å°çœŸèª çš„ä¿¡ï¼Œåˆ†äº«ä½ çš„æƒ³æ³•æˆ–é—œå¿ƒç©å®¶ã€‚ä»¥JSONæ ¼å¼å›æ‡‰ï¼š
{
  "subject": "ä¿¡ä»¶ä¸»é¡Œ",
  "content": "ä¿¡ä»¶å…§å®¹ï¼ˆæº«æš–ã€å€‹äººåŒ–ã€ç¬¦åˆè§’è‰²æ€§æ ¼ï¼‰"
}
      `.trim()

      const result = await this.model.generateContent(prompt)
      const response = await result.response
      const text = response.text()
      
      const cleanText = text.replace(/```json\n?|\n?```/g, '').trim()
      const parsed = JSON.parse(cleanText)
      
      return {
        subject: parsed.subject || 'ä¾†è‡ªå°é®çš„å•å€™',
        content: parsed.content || 'å¸Œæœ›ä½ ä¸€åˆ‡éƒ½å¥½ã€‚',
      }
      
    } catch (error) {
      logger.error('Failed to generate NPC letter:', error)
      
      return {
        subject: 'ä¾†è‡ªå°é®çš„å•å€™',
        content: 'æœ€è¿‘éå¾—å¥½å—ï¼Ÿå°é®ä¾ç„¶æº«æš–å¦‚æ˜”ï¼ŒæœŸå¾…ä¸‹æ¬¡è¦‹é¢ã€‚',
      }
    }
  }

  async generateNPCToNPCConversation(prompt: string): Promise<string> {
    try {
      // æ ¹æ“šé…ç½®é¸æ“‡ä½¿ç”¨ CLI æˆ–ç›´æ¥ API
      if (this.useGeminiCLI) {
        return await this.callGeminiCLI(prompt, null)
      } else {
        const result = await this.model.generateContent(prompt)
        const response = await result.response
        return response.text()
      }
    } catch (error) {
      logger.error('Failed to generate NPC-to-NPC conversation:', error)
      
      // é™ç´šè™•ç† - è¿”å›é è¨­å°è©±
      return JSON.stringify([
        {
          speakerName: 'è‰¾ç‘ª',
          content: 'ä»Šå¤©å¤©æ°£çœŸå¥½å‘¢ã€‚',
          emotionalTone: 'warm'
        },
        {
          speakerName: 'è‰è‰', 
          content: 'æ˜¯å•Šï¼èŠ±åœ’è£¡çš„èŠ±éƒ½é–‹å¾—ç‰¹åˆ¥ç¾éº—ã€‚',
          emotionalTone: 'cheerful'
        }
      ])
    }
  }
}

export const geminiService = new GeminiService()